%% bare_conf_compsoc.tex
%% V1.4b
%% 2015/08/26
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8b or later) with an IEEE Computer
%% Society conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/pkg/ieeetran
%% and
%% http://www.ieee.org/

\documentclass[conference,compsoc]{IEEEtran}
% Some/most Computer Society conferences require the compsoc mode option,
% but others may want the standard conference format.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference,compsoc]{../sty/IEEEtran}

% *** MISC UTILITY PACKAGES ***
%
\usepackage{ifpdf}
\usepackage{framed}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/pkg/ifpdf
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.



% *** CITATION PACKAGES ***
%
\ifCLASSOPTIONcompsoc
  % IEEE Computer Society needs nocompress option
  % requires cite.sty v4.0 or later (November 2003)
  \usepackage[nocompress]{cite}
\else
  % normal IEEE
  \usepackage{cite}
\fi



% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/pkg/graphicx
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/pkg/epslatex
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). The IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
\usepackage{amsmath}
\usepackage{cuted}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics.
%
% Note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/amsmath
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}




% *** SPECIALIZED LIST PACKAGES ***
%
\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as the IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/pkg/algorithms
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/pkg/algorithmicx




% *** ALIGNMENT PACKAGES ***
%
\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/array


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=footnotesize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a sans serif font rather
% than the serif font used in traditional IEEE formatting and thus the need
% to invoke different subfig.sty package options depending on whether
% compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/pkg/subfig
\usepackage{verbatim}
\usepackage{soul}
\usepackage{xcolor}
\newcommand{\TODO}[1]{\hl{TODO: #1}}
\newcommand{\NOTE}[1]{\hl {NOTE: #1}}
\newcommand{\changed}[1]{\textcolor{red}{#1}}


% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure.
% Be aware that LaTeX2e kernels dated 2015 and later have fixltx2e.sty's
% corrections already built into the system in which case a warning will
% be issued if an attempt is made to load fixltx2e.sty as it is no longer
% needed.
% The latest version and documentation can be found at:
% http://www.ctan.org/pkg/fixltx2e


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/stfloats
% Do not use the stfloats baselinefloat ability as the IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that the IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as the IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
% \usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/pkg/dblfloatfix




% *** PDF, URL AND HYPERLINK PACKAGES ***
%
\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/url
% Basically, \url{my_url_here}.

\usepackage{graphicx} % Required for including pictures
\graphicspath{{pics/}} % Specifies the directory where pictures are stored
\usepackage{caption}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{multirow} % make table

\makeatletter % Put Roman Number in Text
\newcommand{\rmnum}[1]{\romannumeral #1}
\newcommand{\Rmnum}[1]{\expandafter\@slowromancap\romannumeral #1@}
\makeatother



% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{Watch Out for the Bully! Job Interference Study on Dragonfly Network}


% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
% \author{\IEEEauthorblockN{Michael Shell}
% \IEEEauthorblockA{School of Electrical and\\Computer Engineering\\
% Georgia Institute of Technology\\
% Atlanta, Georgia 30332--0250\\
% Email: http://www.michaelshell.org/contact.html}
% \and
% \IEEEauthorblockN{Homer Simpson}
% \IEEEauthorblockA{Twentieth Century Fox\\
% Springfield, USA\\
% Email: homer@thesimpsons.com}
% \and
% \IEEEauthorblockN{James Kirk\\ and Montgomery Scott}
% \IEEEauthorblockA{Starfleet Academy\\
% San Francisco, California 96678-2391\\
% Telephone: (800) 555--1212\\
% Fax: (888) 555--1212}}


\author{

\IEEEauthorblockN{Xu Yang\IEEEauthorrefmark{1}, John Jenkins\IEEEauthorrefmark{2}, Misbah Mubarak\IEEEauthorrefmark{2}, Robert B. Ross\IEEEauthorrefmark{2}, Zhiling Lan\IEEEauthorrefmark{1}}

\IEEEauthorblockA{\IEEEauthorrefmark{1}Department of Computer Science,
Illinois Institute of Technology,
Chicago, Illinois, USA 60616\\
\{xyang56\}@hawk.iit.edu, lan@iit.edu}

\IEEEauthorblockA{\IEEEauthorrefmark{2}Mathematics and Computer Science Division, Argonne National Laboratory,
Argonne, IL, USA 60439\\
\{jenkins,rross\}@mcs.anl.gov, mmubarak@anl.gov}
}


% conference papers do not typically use \thanks and this command
% is locked out in conference mode. If really needed, such as for
% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
% after \documentclass

% for over three affiliations, or if they all won't fit within the width
% of the page (and note that there is less available width in this regard for
% compsoc conferences compared to traditional conferences), use this
% alternative format:
% 
%\author{\IEEEauthorblockN{Michael Shell\IEEEauthorrefmark{1},
%Homer Simpson\IEEEauthorrefmark{2},
%James Kirk\IEEEauthorrefmark{3}, 
%Montgomery Scott\IEEEauthorrefmark{3} and
%Eldon Tyrell\IEEEauthorrefmark{4}}
%\IEEEauthorblockA{\IEEEauthorrefmark{1}School of Electrical and Computer Engineering\\
%Georgia Institute of Technology,
%Atlanta, Georgia 30332--0250\\ Email: see http://www.michaelshell.org/contact.html}
%\IEEEauthorblockA{\IEEEauthorrefmark{2}Twentieth Century Fox, Springfield, USA\\
%Email: homer@thesimpsons.com}
%\IEEEauthorblockA{\IEEEauthorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212, Fax: (888) 555--1212}
%\IEEEauthorblockA{\IEEEauthorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}




% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract
\begin{abstract}

The high-radix, low-diameter dragonfly network will be the choice of many computing facilities for building their next generation supercomputers. Preliminary studies show that random placement with adaptive routing should be the rule of thumb to utilize such networks, since random placement with adaptive routing can uniformly distribute traffic over the network and alleviate congestion. However, in this paper, we made the observation that while random placement coupled with adaptive routing can load-balance the network when multiple jobs are running concurrently, they can not guarantee the best performance for each single job. The performance improvement of communication-intensive jobs comes with the sacrifice of less intensive jobs. We refer this phenomenon as ``bully" between concurrently running jobs. We presented a detailed analysis about this ``bully" behavior between jobs at the network level based on a sophisticated, high-fidelity discrete even-driven simulation tool. The observations and analysis presented in this work illuminate a path to the adoption of more efficient job placement policy and routing algorithm for HPC systems with dragonfly network.  

\end{abstract}

% no keywords

% \keywords{Dragonfly, Job placement, Routing, Interference}



% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}
\label{sec:intro}

The low latency and high bandwidth interconnect network plays a critical role in HPC system performance. As computational capabilities continue to grow due to many-core nodes with accelerators, the network is increasingly becoming a scare resources. The high-radix, low-diameter dragonfly topology can lower the \NOTE{?} cost of the interconnect, improve network bandwidth and reduce packet latency \cite{dally-dragonfly}. This make the dragonfly network an very promising choice for building petaflop and beyond supercomputers. 
%The procurement results from Trinity and CORAL project shows the great performance improvement can be got from using dragonfly network. 


While dragonfly topologies provide low-latency and high-bandwidth networking, efficiently utilizing it is a significant concern. In particular, intelligent job placement to avoid interference is of paramount importance to guarantee the performance of each job when it shares network resources with other concurrently running peers \cite{bhatele2015, dskinner}. Recent studies suggest that random job placement coupled with adaptive routing can alleviate local congestion, eliminate hot-spots and reach load-balance for dragonfly networks \cite{jain-sc14, bhatele-sc11, brandt2014}. 


In this work, we study the interference between concurrently running jobs on dragonfly networks with different job placement and routing policies. We use CODES, an HPC network simulation toolkit with high fidelity and excellent scalability for packet level simulation \cite{codes}. Unlike much existing work that rely on synthetic workloads, we use traces of three representative applications from the DOE Design Forward Project \cite{designforwardwebpage}. The advantage of using real application traces is straight forward: \TODO{ these traces can capture application communication behavior in detail that usually omitted in synthetic workload for the purpose of simplicity}. Applications usually are distinctive from each other in terms of data transfer amount, communication pattern, operation dependency etc. which can be impractical to reproduce in a synthetic workload.

We conduct extensive experiments with three applications running on dragonfly network with two job placement policies and three routing policies. We analyze the applications' performance in terms of communication time when running with different placement and routing configurations. Our evaluation is based on more than 1000 runs of simulation. Through extensive simulation with application traces, we make several interesting observations. 


%We made observation from our extensive study that, when dragonfly network is configured with random placement and adaptive routing scheme in order to reach hot-spots free and load balance, the performance of particular job(s) in the workload would suffer degradation. The communication intensive jobs in the workload can benefit from random placement and adaptive routing, with great performance improvement. Unfortunately, those less intensive jobs are the sacrifices for this improvement, their performance will be greatly reduced. We identify this phenomenon as ``bully" between concurrently running jobs.

\begin{itemize}
   
    \item Random placement coupled with adaptive routing can uniformly distribute traffic over the network, avoid hot-spots and alleviate traffic congestion. The network could reach the optimal performance by using random placement and adaptive routing. 

    \item ``Bully" behavior is happening between concurrently running jobs on dragonfly network when random placement and adaptive routing in use. The performance improvement obtained by communication-intensive jobs come with the cost of less intensive jobs suffering performance degradation.

    \item Contiguous placement coupled with minimal routing can guarantee consistency performance of each job by prohibiting network resource sharing, though it results in local network congestion and unbalanced network utilization. Contiguous placement and minimal routing are preferred by less communication-intensive jobs, since it will prevent them from being ``bullied" by other communication-intensive jobs.
    
\end{itemize}

%These observations also reconfirm that interference between concurrently running jobs would make the performance of some jobs very unpredictable. The detailed analysis about the traffic and congestion in network level unveil the undercurrent beneath that interference. 

Based on our observations, the optimal job placement and routing solution for the workload running dragonfly system should be specific to job communication intensity. \emph{The random placement and adaptive routing are preferable to communication-intensive jobs, while the less intensive jobs should run with contiguous placement and minimal routing.} To the best of our knowledge, using parallel application traces from production systems for the study of job interference on dragonfly network has not been reported so far. We believe the observations and analysis presented in this paper are valuable to a number of communities including HPC computing centers, system software developers, and system administrators. The computing centers could choose the configuration for implementing a dragonfly network with consideration about resource sharing between concurrently running jobs. System software such as workload manager could come up with better scheduling algorithm for jobs with distinctive communication behavior. And system administrators could be able to make accurate predication about system availability with the knowledge of jobs running status under different placement and routing configurations.

The rest of this paper is organized as follows. Section \ref{sec:background} describes the dragonfly network and the placement and routing policies. Section \ref{sec: methodology} talks about the use of CODES as research vehicle and three representative applications from the DOE Design Forward Project. Section \ref{sec:workload-1} presents the analysis of three applications running on a dragonfly network with different placement and routing configurations. Section \ref{sec:workload-2} validates the observations we get in section \ref{sec:workload-1}. Section \ref{sec:related work} discusses the related work. Finally, the conclusion is presented in Section \ref{sec:conclusion}.

\section{Background}
\label{sec:background}

In this section, we review the dragonfly topology, including the placement and routing policies examined in previous work. 

\subsection{Dragonfly Network}
\label{sec:network}
The dragonfly is a two-level hierarchical topology. It consists of several groups connected by all-to-all links. In each group, there could be ``a" number of routers connected via all-to-all local channels. For each router, there could be ``p" number of compute nodes attached to it via terminal links. The router has ``h" number of global channels that used as intergroup connections through which the router connected to other routers in different groups. Thus, the radix of each router is $k = a+h+p-1$. The implementation of such dragonfly network could choose different value for ``a", ``p" and ``h" in different computing centers. The adoption of proper $a$, $h$, $p$ could be involving many factors, such as system scale, building cost and workload requirements. 

For the purpose of load balance, it is recommended that the proper dragonfly configuration should follow $a=2p=2h$\cite{kim-micro}. Under this configuration, the total number of groups ``g" in the dragonfly network would be $g = a*h+1 $, the total number of compute nodes ``N" in the network would be $N = p*a*g $. An implementation of dragonfly network follows such configuration is illustrated in Figure \ref{fig:dragonfly-overview}. There are 6 routers in each group, each router has 3 compute nodes attached to it. This dragonfly implementation consists of 19 groups and 342 nodes in total.

\begin{figure}[h!] 
  \centering
  \includegraphics[width=0.48\textwidth]{dragonfly-overview}
  \caption{Dragonfly Network Overview. Illustration of part of dragonfly network. There are 19 groups, 6 routers in each group, 3 compute nodes connected to each router, 342 nodes in total. Job $J1$ requires for 7 nodes, gets its allocation by random placement. Job $J2$ requires for 8 nodes, gets its allocation by contiguous placement. }
  \label{fig:dragonfly-overview}
\end{figure}


\subsection{Job Placement on Dragonfly}
\label{sec:placement-schemes}

For a parallel application requiring multiple compute nodes, job placement policy refers to the way of assigning the tasks of the application onto the system by a system software such as batch scheduler \cite{xu-cluster14}. In this work, we study two alternative placement policies considered by the community for dragonfly systems: 

%Job placement refers to the scheme used by batch scheduler to allocate the required number of nodes by each job for execution. As studied by several researchers, the job placement could be an important factor that impact application performance \cite{hoefler-hpdc14} \cite{bhatele-sc11} \cite{jain-sc14}. In this work, we study the following two placement schemes that are most likely to be deployed in the future dragonfly system.

\textbf{Contiguous Placement:} In this policy, the compute nodes are assigned to job in a consecutive manner. The assignment fills up a group first, only crosses group boundaries and start to fill the next group as necessary. Job $J2$, illustrated as blue in Figure \ref{fig:dragonfly-overview}, gets the required amount of nodes by contiguous placement. Contiguous placement confines the tasks of a job into the same group, which may result in local network congestion and increase the possibility of hot-spots. 

\textbf{Random Placement:} In this policy, job will get a set of nodes that randomly selected from all the available nodes in the system. The nodes assigned to each job would be attached to different routers in different groups, as illustrated in Figure \ref{fig:dragonfly-overview} the red nodes assigned to job $J1$. Some routers may be shared by different jobs when random placement in use. Random placement can distribute the tasks of  a job uniformly across the whole system, thus avoid the possible local congestion and reach load balance. However, random placement may cause possible congestion on global links.


\subsection{Routing on Dragonfly}
\label{sec:routing-schemes}
The routing policy refers to the strategy adopted to route messages \NOTE{(message refers to a stream of packets)} from the source router to the destination router. Previously studied routing policies for dragonfly network include minimal routing, adaptive routing \cite{dally-dragonfly}, and progressive adaptive routing\cite{jiang}, and some of their variations \cite{won-prog-adaptive}. In this work we study three widely adopted routing policies on dragonfly networks.

\textbf{Minimal:} In this policy, a message from source router will take the the shortest path to the destination router. When there are multiple shortest paths between the source and destination router, the message will be evenly divided among the paths. Minimal routing can guarantee the minimum hops the message takes from source to destination. However, it may result in congestion along the shortest path. 


\textbf{Adaptive:} In this policy, the path a message takes will be adaptively chosen between shortest and non-shortest path, depends on the congestion situation along that path. For the non-shortest path, an intermediate router will be randomly chosen. The message will first take the shortest path from source to that intermediate router, then it will take the shortest path from that intermediate router to the destination. Since routing path are chosen adaptively based on the congestion situation, it can avoid local congestion and possible hot-spots. Adaptive routing collapses to minimal routing in the absence of traffic congestion. 

\textbf{Progressive Adaptive:} In this policy, the decision to route minimally at each hop in the source group will be re-evaluated. And any decision to route non-minimally at source router or at a subsequent hop is permanent and won't be re-evaluated \cite{jiang}. The progressive adaptive is capable of handling the case where a global link is congested but this information has not yet propagated back to the source router \cite{jiang}. The packet will take the non-minimal route only when the congestion is encountered. 



\section{Methodology}
\label{sec: methodology}

It is difficult to do experiment with concurrently running jobs on HPC system\cite{zhou-ipdps-2015}\cite{jain-sc14}\cite{bhatele-sc11}\cite{jokanovic-ipdps-2015}. One reason is that job placement and routing policies are part of system configuration, it is impossible for user to make changes at will. Another reason is that it is unrealistic to reserve the system exclusively to run the same batch of jobs with desired placement and routing configurations and compare the results. Last but not least, configurable dragonfly networks that allow us to perform the exploration presented in this paper are hard to come by for the time being. Therefore, we resort to simulation in our work.

\subsection{Simulation Tool}
\label{sec:simulation-tool}
A simulation toolkit named CODES, Co-Design of Multilayer Exascale Storage Architectures, enables the exploration of simulating different HPC networks with high fidelity and great scalability \cite{codes}. CODES supports dragonfly network\cite{codes-dragonfly} \cite{misbah-tpds}, as well as other topologies such as torus\cite{misbah-pads-2014}\cite{ning-pads-2011} and fat-tree\cite{ning-pads-2015}, with packet-level high-fidelity simulation. It can drive these models through an MPI simulation later that utilizing DUMPI traces\cite{sst}. In this work, we perform an in-depth analysis of job interference with different job placement and routing policies on dragonfly network.

\subsection{Parallel Applications}
\label{sec: application traces}

We choose three representative parallel applications from the DOE Design Forward Project\cite{designforwardwebpage}. We believe these applications can be representative of a wide array of applications running on leadership-class supercomputers. Specifically, we study the \emph{Algebraic MultiGrid Solver} (AMG), \emph{Geometric Multigrid V-Cycle from production elliptic solver} (MultiGrid) and \emph{Crystal Router MiniApp} (CrystalRouter). 

\textbf{AMG:} The Algebraic MultiGrid Solver is a parallel algebraic multi-grid solver for linear systems arising from problems on unstructured mesh physics packages. It has been derived directly from the BoomerAMG solver that is being developed in the Center for Applied Scientific Computing (CASC) at LLNL \cite{amg}. 


\textbf{MultiGrid:} The geometric multi-grid v-cycle from the production elliptic solver BoxLib is a software framework for massively parallel block-structured adaptive mesh refinement (AMR) codes \cite{boxlib}. It is widely used for structured grid physics packages. 

\textbf{CrystalRouter:} The CrystalRouter MiniApp is the communication kernel of the full application Nek5000 \cite{nek5000}, which is a spectral element CFD application developed at Argonne National Laboratory. It features spectral element multi-grid solvers coupled with a highly scalable, parallel coarse-grid solver that is widely used for projects including ocean current modeling, thermal hydraulics of reactor cores, and spatiotemporal chaos. 




\subsection{System Configuration}
\label{sec: simulation configuration}

\NOTE{justify network size}The dragonfly network studied in this work consists of 33 groups, each group contains 8 routers and each router has 4 compute nodes attached to it. Overall, there are 264 routers and 1056 compute nodes in the network. The ratio between aggregated local and global channel bandwidth are set propotional to the Cray Cascade system\cite{faanes} based on the dragonfly topology\cite{dally-dragonfly}.

In this work, we study both the network behavior and the job interference when dragonfly network is configured with 6 different job placement and routing policy combinations, which are summarized in Table \ref{tab: placement routing configs}. 

\begin{table}[ht]
\begin{center}
\caption{The notation for different placement and routing configurations} 
\label{tab: placement routing configs}
%\centering % Centers the table on the page, comment out to left-justify
\begin{tabular}{l c c c }
\toprule % Top horizontal line
\toprule
&\multicolumn{3}{c}{Routing Policies} \\ % Amalgamating several columns into one cell is done using the \multicolumn command as seen on this line
\cmidrule(l){2-4}
Placement Policies & Minimal & Adaptive & Progressive Adaptive\\ % Column names row
\midrule % In-table horizontal line
Contiguous  &  CM   &   CA   &  CPA   \\ % Content row 1
\midrule
Random  &   RM  &   RA   &  RPA   \\ 
\midrule % In-table horizontal line
\bottomrule % Bottom horizontal line
\end{tabular}
\end{center}
\end{table}


%Our analysis focuses on both overall network workload and individual application performance. For overall workload analysis, we focus on the time spent on communication by the workload, the network traffic throughput and busy time of links and channels. For individual application analysis, we study the time spent on communication by each MPI rank, traffic and busy time of each router that belongs to specific application. In our experiments, we collect and analyze the following data: 
Our analysis focus on the following metrics:
\begin{itemize}

    \item \textbf{Network Traffic:} The traffic refers to the amount of data go through each router in the network. For each router, the traffic go through its terminal link, local channel and global channel are analyzed respectively.
    
    \item \textbf{Network Saturated Time:} The saturated time refers to the time period when  the buffer of certain port in the router is full. Saturated time can denote the congestion on certain port.
    
    \item \textbf{Communication Time:} The communication time of each MPI rank refers to the time spent by the rank to complete its message exchange with all other ranks. For each job, this metric refers to the time spent to complete the message exchange by all its ranks.

\end{itemize}

\NOTE{limitations:}Since our study is about network behavior and job interference during communication, the time spent by each MPI rank on computation will not be counted in our experiments. 

With respect to random placement, we conduct our experiments with 50 sets of distinctive allocation generated by random placement. The corresponding experimental results are median chosen, which intended to eliminate the possibility of variation.



%\subsection{Workload Combinations}
%\label{sec:workload-combination}
%
%We come up with two parallel workloads. The first workload consists of the original application traces described in Section \ref{sec: application traces}, while the second workload is a modified version of the first workload for the purpose of validation. 
\subsection{Workload Summary}
\label{sec:workload summary}




%In this work, we use two sets of parallel workloads to quantified study the network behavior as well as job interference when the dragonfly network equipped with different placement and routing configurations. 

In this study, we use two sets of parallel workloads. Workload \Rmnum{1} consists of AMG, MultiGrid and CrystalRouter. As we see in Table \ref{tab:apps-detail}, AMG has the least amount of data transfer, thus contributes the least amount of traffic in Workload \Rmnum{1}. Workload \Rmnum{2} consists of sAMG, MultiGrid and CrystalRouter. sAMG is a synthetic version of AMG, which is the same as AMG in every aspect expect that the data transfer amount 100x greater than AMG. sAMG contributes the dominant amount of traffic in Workload \Rmnum{2}. 

Workload \Rmnum{1} is used to identify the ``bully" behavior between concurrently running jobs on dragonfly network. Workload \Rmnum{2} is used to verify the results and conclusion obtained from the study about Workload \Rmnum{1}.

Table \ref{tab:apps-detail} summarizes the details of each application. It shows the number of MPI ranks, the average data transfer amount of each rank and the total data transfer amount for each application.

\begin{table}[ht]
\begin{center}
\caption{The details of each application.} 
\label{tab:apps-detail}
%\centering % Centers the table on the page, comment out to left-justify
\begin{tabular}{l c c c }
\toprule % Top horizontal line
\toprule
&\multicolumn{3}{c}{Application Details} \\ % Amalgamating several columns into one cell is done using the \multicolumn command as seen on this line
\cmidrule(l){2-4}
App Name & Num. Rank & Avg. Data/Rank & Total Data\\ % Column names row
\midrule % In-table horizontal line
AMG  &    216 &   0.6MB   &     130MB\\ % Content row 1
\midrule
MultiGrid  &    125 &   5MB   &     625MB\\ 
\midrule
CrystalRouter  &   100  &  35MB    &     3500MB\\ 
\midrule
sAMG  &    216 &   60MB   &     13000MB\\ % Content row 1
\midrule % In-table horizontal line
\bottomrule % Bottom horizontal line
\end{tabular}
\end{center}
\end{table}



\section{Study of Parallel Workload \Rmnum{1 }}
%\section{Identify the ``Bully"}
\label{sec:workload-1}

We study the network behavior as well as application interference under different placement and routing configurations from two perspectives. First, we analyze the network performance in terms of workload communication time. Then, we isolate each application from the workload, and analyze the interference by scrutinizing the traffic go through the routers that serving each application.


% \begin{figure}[h!]
%   \centering
%   \includegraphics[width = 0.48\textwidth ]{data_amount}
%   \caption{Applications Data Transfer Amount. AMG has the least amount of data transfer, compared with MultiGrid and CrystalRouter.\NOTE{y axis in log?} }
%   \label{fig:3app-data-amount}
% \end{figure}
% 
% Figure \ref{fig:3app-data-amount} shows the data transfer amount of each MPI rank of three application. Based on this figure, we can tell that CrystalRouter is the most communication-intensive and AMG is the lest communication-intensive. 



\subsection{Network Performance Analysis}
%  
% \begin{figure}[h!]
%   \centering
%   \includegraphics[width = 0.48\textwidth ]{wkld/wkld-commtime}
%   \caption{Time spent on communication by Workload I when 6 different placement and routing configurations are used. Random is better than contiguous in terms of improving communication efficiency. Communication time can be further reduced when (progressive) adaptive routing is used under both placement schemes. }
%   \label{fig:wkld-commtime}
% \end{figure}

\begin{table}[ht]
\begin{center}
\caption{Time spent on communication by Workload I when dragonfly network equipped with 6 different placement and routing configurations.} 
\label{tab:wkld-commtime}
%\centering % Centers the table on the page, comment out to left-justify
\begin{tabular}{l c c c c c c }
\toprule % Top horizontal line
\toprule
&\multicolumn{6}{c}{Placement and Routing Configurations} \\ % Amalgamating several columns into one cell is done using the \multicolumn command as seen on this line
\cmidrule(l){2-7}
	 & CM & CA & CPA & RM & RA & RPA \\ % Column names row
\midrule % In-table horizontal line
Time(ms)  &  1870 & 1250 & 1248 & 860 & 835 &830\\ % Content row 1

\midrule % In-table horizontal line
\bottomrule % Bottom horizontal line
\end{tabular}
\end{center}
\end{table}

The communication time spent by Workload \Rmnum{1} under different placement and routing configurations shown in Table \ref{tab:wkld-commtime}. The contiguous placement coupled with minimal routing (CM) results in highest communication time. When contiguous placement coupled with progressive adaptive and adaptive routing (CA, CPA), Workload \Rmnum{1} spends  comparable amount of time to complete communication. The random placement policy performs comparably with all routing policies and outperforms all contiguous placement configurations.

\begin{figure*}[t!]
    \centering
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{wkld/gc-traffic}
        \caption{Global Channel Traffic}
        \label{fig:global-channel-traffic}
    \end{subfigure}\hfill
    \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{wkld/lc-traffic}
        \caption{Local Channel Traffic}
        \label{fig:local-channel-traffic}
    \end{subfigure}\hfill
    \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{wkld/tl-traffic}
        \caption{Terminal Link Traffic}
        \label{fig:terminal-link-traffic}
    \end{subfigure}\\

    \centering   
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{wkld/gc-stime}
        \caption{Global Channel Busy Time}
        \label{fig:global-channel-stime}
    \end{subfigure}\hfill
     \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{wkld/lc-stime}
        \caption{Local Channel Busy Time}
        \label{fig:local-channel-stime}
    \end{subfigure}\hfill
    \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{wkld/tl-stime}
        \caption{Terminal Link Busy Time}
        \label{fig:terminal-link-stime}
    \end{subfigure}%
   \caption{The aggregate traffic and saturated time of links in different level in the dragonfly network when Workload \Rmnum{1} running under 6 different placement and routing configurations. ``CA" and ``CPA" have comparably same performance and the corresponding lines are overlapped. }
   \label{fig:wkld-network-traffic-stime}
\end{figure*}

Figure \ref{fig:wkld-network-traffic-stime} shows the aggregate traffic for terminal links, local channels and global channels, and the corresponding saturated time when Workload \Rmnum{1} running on dragonfly network with 6 different placement and routing configurations. 

%global link traffic and busy time explanation
When Workload \Rmnum{1} running with contiguous placement and minimal routing(CM), all its traffic is happening in the contiguously allocated groups, causing congestion along certain shortest paths from source routers to destination routers. Both the traffic through the global channels in those congested paths and the corresponding saturated time are the highest compared with other configurations, shown as the blue dashed line in Figure \ref{fig:global-channel-traffic} and \ref{fig:global-channel-stime}.
When contiguous placement is coupled with (progressive) adaptive routing (CA and CPA), the traffic through congested global channels will be greatly reduced, so does corresponding saturated time, shown as the red and green dashed line in Figure \ref{fig:global-channel-traffic} and \ref{fig:global-channel-stime}. Since (progressive) adaptive routing are congestion aware, the traffic would be redirected to the intermediate routers in other idle groups when congestion occurs, thus the traffic burden on the contiguously allocated groups will be alleviated. 


Random placement policy performs comparably with three different routing policies.
Shown as the solid lines in Figure \ref{fig:global-channel-traffic}, the traffic go through global channels are quite balanced across all the routers in the network, thus no particular global channel will suffer high traffic burden. When the random placements coupled with minimal routing (RM), the packets can avoid unnecessary intermediate forwarding as introduced by adaptive and progressive routing, which results in generating less traffic. That's why the blue solid line is lower than the red and green solid line. Since the random placement can uniformly distribute traffic, there are no sudden surge of saturated time of global channel over the network, shown as solid lines in Figure \ref{fig:global-channel-stime}. 

%local channel traffic and busy time explanation

We observe similar phenomena from the local channel traffic (Figure \ref{fig:local-channel-traffic}) and saturated time (Figure \ref{fig:local-channel-stime}). Contiguous placement coupled with minimal routing (CM) results in local congestion, and thus high aggregate traffic on the local channels of certain routers. Even with adaptive or progressive adaptive routing, the local congestion caused by grouping all MPI ranks in the same group(s) in contiguous placement can not be eliminated. Random placement is effective at addressing this type of congestion. 

%terminal link traffic and busy time explanation
Figure \ref{fig:terminal-link-traffic} is for the purpose of symmetry, it shows the traffic per rank (aka traffic through terminal links), which won't change when different placement and routing configurations in use. All 6 lines are overlapped in Figure \ref{fig:terminal-link-traffic}. However, due to the traffic changes on global and local channels, the saturated time of terminal links will experience variability when different routing schemes in use, as shown in Figure \ref{fig:terminal-link-stime}. When contiguous placement coupled with minimal routing(CM), the accumulated congestion on local and global channels cause extremely long saturated time on the terminal link, shown as the blue dashed line in Figure \ref{fig:terminal-link-stime}. This again manifests the severe congestion caused by using contiguous placement and minimal routing. 


 
% \NOTE{The take-home message} from Figure \ref{fig:wkld-network-stime} and \ref{fig:wkld-network-traffic}. 

%MPI ranks are assigned to physical nodes that are adjacent to each other in contiguous placement, which confines the workload traffic to certain local area when coupled with minimal routing. This may result in local congestion and unbalanced network utilization. Contiguous placement coupled with minimal routing always leads to the extreme high traffic amount for some routers , and thus longest saturated time.

%Random placement allocates MPI ranks to a set of randomly selected nodes all over the system, uniformly distributes workload traffic and avoids local congestion. When random placement is coupled with minimal routing, the packets will take the shortest path from source router to the destination router without routing to any intermediate routers, this will prevent the routing from generating extra traffic. When random placement is coupled with adaptive or progressive adaptive routing, the possibility of any congestion will be further reduced at the cost of extra intermediate traffic. 

%The random job placement coupled with either minimal or adaptive routing can reach hot-spots free and load-balanced by distributing the workload traffic over the network. The workload performance get greatly improved with this configuration. However, when we isolated individual application from the workload, we unveil the fact that not every application can benefit from random job placement. 



\subsection{Individual Application Analysis}

\begin{figure*}[t!]
    \centering
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.5 in]{wkld/amg/commtime}
        \caption{AMG Communication Time}
        \label{fig:amg-commtime}
    \end{subfigure}%
    \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.5 in]{wkld/mg/commtime}
        \caption{MG Communication Time}
        \label{fig:mg-commtime}
    \end{subfigure}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.5 in]{wkld/cr/commtime}
        \caption{CR Communication Time}
        \label{fig:cr-commtime}
    \end{subfigure}%
   \caption{Application communication time. Three applications running concurrently on dragonfly network with different placement and routing configurations. Random placement and adaptive routing can improve MG and CR communication, however, AMG's communication time is greatly prolonged.}
   \label{fig:apps-commtime}
\end{figure*}

Figure \ref{fig:apps-commtime} shows the distribution of communication time of three applications in per rank manner, when they running concurrently under 6 different placement and routing configurations listed in Table\ref{tab: placement routing configs}.

As shown in Figure \ref{fig:mg-commtime}, \ref{fig:cr-commtime}, MultiGrid and CrystalRouter suffer the longest communication time when running with contiguous placement and minimal routing (CM). When contiguous placement coupled with adaptive or progressive adaptive routing (CA, CPA), the communication time of both MultiGrid and CrystalRouter is significantly reduced. Random placement further reduces their communication time, and reaches the best performance when coupled with (progressive) adaptive routing (RPA, RA). Both MultiGrid and CrystalRouter show the same trend as the workload when running under different placement and routing configurations. 

AMG is quite an exception. As shown in Figure \ref{fig:amg-commtime}, the communication time of AMG skyrockets when running under random placement coupled with (progressive) adaptive routing (RPA, RA). The contiguous placement coupled with (progressive) adaptive routing can reach the best performance for AMG. The performance of AMG running under contiguous placement coupled with minimal routing (CM) is no better than random coupled with minimal routing (RM), but still much better than random with (progressive) adaptive routing (RPA, RA). 



\begin{figure*}[t]
    \centering
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{wkld/amg/lc-traffic}
        \caption{AMG Local Channel Traffic}
        \label{fig:amg-lc-traffic}
    \end{subfigure}\hfill
    \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{wkld/mg/lc-traffic}
        \caption{MG Local Channel Traffic}
        \label{fig:mg-lc-traffic}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{wkld/cr/lc-traffic}
        \caption{CR Local Channel Traffic}
        \label{fig:cr-lc-traffic}
    \end{subfigure}\\

    \centering
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{wkld/amg/gc-traffic}
        \caption{AMG Global Channel Traffic}
        \label{fig:amg-gc-traffic}
    \end{subfigure}\hfill
    \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{wkld/mg/gc-traffic}
        \caption{MG Global Channel Traffic}
        \label{fig:mg-gc-traffic}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{wkld/cr/gc-traffic}
        \caption{CR Global Channel Traffic}
        \label{fig:cr-gc-traffic}
    \end{subfigure}%
   \caption{The aggregate traffic go through the local and global channels of routers belonging to specific application. ``CA" and ``CPA" have comparably same performance and the corresponding lines are overlapped.}
   \label{fig:3app-lc-gc-traffic}
\end{figure*}


% Show the evidence from network level, explain why AMG is different. 
We look into network level to identify the culprit behind AMG's abnormal behavior with random placement and adaptive routing. By identifying the compute nodes each MPI rank resides on and routers that serving each application, we can see that the traffic go through the routers serving AMG skyrockets when random placement and adaptive routing is in use, shown in Figure \ref{fig:amg-lc-traffic} and \ref{fig:amg-gc-traffic}. Adaptive routing will redirect the traffic of other applications to go through the routers belonging to AMG, and increase the traffic burden on those routers, thus slow down the communication of AMG.

No router will be shared between applications under contiguous placement. A number of successive groups will be allocated to the same application under contiguous placement policy. When contiguous placement coupled with minimal routing, application will be free of interference from its concurrently running peers. However, application communication traffic will be confined within their allocated groups, thus congestion is very likely to happen depending on application communication intensity. As the lest communication-intensive application in Workload \Rmnum{1}, AMG can benefit from contiguous placement. Under contiguous placement, the traffic go through the local and global channels of the routers belonging to AMG is significantly lower than with random placement, shown in Figure \ref{fig:amg-lc-traffic}, \ref{fig:amg-gc-traffic}. 

MultiGrid and CrystalRouter are more communication-intensive compared with AMG. They will suffer congestion on both local and global channels when contiguous placement is in use, shown as the dashed line in Figure \ref{fig:mg-lc-traffic}, \ref{fig:mg-gc-traffic} and Figure \ref{fig:cr-lc-traffic}, \ref{fig:cr-gc-traffic}. On the other hand, the random placement can uniformly distribute their traffic all over the network, alleviate the possible congestion, shown as the solid lines in Figure \ref{fig:mg-lc-traffic}, \ref{fig:mg-gc-traffic} and Figure \ref{fig:cr-lc-traffic}, \ref{fig:cr-gc-traffic}.


So far we know that the reason for AMG being the only victim from random placement \& adaptive routing is due to its relatively small amount of data transfer, that make it the least communication-intensive application in the workload.

\subsection{Key Findings}
We can get the following key findings from the detailed analysis of three applications. 

\emph{Random placement \& adaptive routing is quite efficient for orchestrating the traffic load in the network by uniformly distributing the workload traffic all over the network. However, application like AMG will be impaired in this orchestration. Beneath the facade of harmony, less communication-intensive application are ``bullied" by their concurrently running communication-intensive peers in the workload. }

% The routers through which the less communication-intensive application traffic used to route, now have more traffic go through them. These extra traffic are from other communication-intensive applications.

\emph{Random placement \& adaptive routing can not guarantee the qualify of service for each application in the workload. In order to reach load-balanced and hot-spots free over the whole network, the traffic from congested routers will be redirected to other less busy routers. This will indulge the ``bully" that communication-intensive applications impose to their less intensive peers.}

\emph{Contiguous placement \& minimal routing guarantee a consistent performance of each application. Although, contiguous placement and minimal routing usually results in local congestion and unbalanced network utilization, it can reduce the interference between concurrently running applications, thus prevent less communication-intensive application from being ``bullied" by its communication-intensive peers.}

We have tried three different congestion sensing schemes that used in adaptive routing\cite{won-prog-adaptive}, although there are some variations between the results, none of the congestion sensing scheme can prevent the ``bully" from happening.

% \section{Parallel Workload \Rmnum{2 }}
\section{``Bully" become ``Bullee"}
\label{sec:workload-2}


In order to prove that AMG being bullied only because it is less communication-intensive than its concurrently running peers, we generate a synthetic application, sAMG, which are same the with AMG's original traces in every aspect expect that the data transfer amount 100x greater than AMG. We run the new workload that consists of sAMG, MultiGrid and CrystalRouter on the same dragonfly network with the same placement \& routing configurations. As shown in Table \ref{tab:apps-detail}, sAMG become the most communication-intensive application in the new workload. 

\subsection{Network Performance Analysis}


\begin{table}[ht]
\begin{center}
\caption{Time spent on communication (MilliSecond) by Workload II when 6 different placement\&routing configuration in use.} 
\label{tab:syn-wkld-commtime}
%\centering % Centers the table on the page, comment out to left-justify
\begin{tabular}{l c c c c c c }
\toprule % Top horizontal line
\toprule
&\multicolumn{6}{c}{Placement\&Routing Configuration} \\ % Amalgamating several columns into one cell is done using the \multicolumn command as seen on this line
\cmidrule(l){2-7}
	 & CM & CA & CPA & RM & RA & RPA \\ % Column names row
\midrule % In-table horizontal line
Runtime  &  6123 & 3231 & 3725 & 2544 & 3701 & 3228 \\ % Content row 1

\midrule % In-table horizontal line
\bottomrule % Bottom horizontal line
\end{tabular}
\end{center}
\end{table}


The communication time spent by parallel workload \Rmnum{2} under different placement \& routing configurations shown in Table \ref{tab:syn-wkld-commtime}. As the overall traffic increased in the workload(due to sAMG), the time spent on communication under each configuration also increases. But the performance of each configuration still keep the same trend as parallel workload \Rmnum{1}. The contiguous placement coupled with minimal routing results in highest communication time. The random placement coupled with minimal routing is the most efficient. Progressive adaptive routing is better than adaptive routing when random placement is in use. And they have comparable results when coupled contiguous placement. 


Figure \ref{fig:synwkld-network-traffic-stime} show the network status when Workload \Rmnum{2} running under different placement \& routing configurations. Contiguous placement coupled with minimal routing result in most traffic go through certain local and global channel, thus the longest  communication time for terminal link, local and global channel. When coupled with (progressive) adaptive routing, the local congestion can get alleviated in contiguous placement. The random placement reach the comparable performance with any routing schemes in terms of both traffic and busy time. They are better than contiguous \& minimal configuration, but not too much improvement against contiguous\&(progressive) adaptive configuration.



\begin{figure*}[t]
    \centering
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{syn-wkld/gc-traffic}
        \caption{Global Channel Traffic}
        \label{fig:synwkld-global-channel-traffic}
    \end{subfigure}\hfill
    \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{syn-wkld/lc-traffic}
        \caption{Local Channel Traffic}
        \label{fig:synwkld-local-channel-traffic}
    \end{subfigure}\hfill
    \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{syn-wkld/tl-traffic}
        \caption{Terminal Link Traffic}
        \label{fig:synwkld-terminal-link-traffic}
    \end{subfigure}\\

    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{syn-wkld/gc-btime}
        \caption{Global Channel Busy Time}
        \label{fig:synwkld-global-channel-stime}
    \end{subfigure}\hfill
     \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{syn-wkld/lc-btime}
        \caption{Local Channel Busy Time}
        \label{fig:synwkld-local-channel-stime}
    \end{subfigure}\hfill
    \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{syn-wkld/tl-btime}
        \caption{Terminal Link Busy Time}
        \label{fig:synwkld-terminal-link-stime}
    \end{subfigure}%
   \caption{Traffic and Saturated Time of different level of links in the dragonfly network. The Workload \Rmnum{2} running under 6 different placement \& routing configuration.}
   \label{fig:synwkld-network-traffic-stime}
\end{figure*}

\subsection{Individual Application Analysis}

The communication time of each application shown in Figure \ref{fig:syn-apps-commtime}. The ``bully" become the ``bullyee". The less communication-intensive applications in Workload \Rmnum{2} are  MultiGrid and CrystalRouter.  When random placement coupled with (progressive) adaptive routing is used, MultiGrid and CrystalRouter suffer prolonged communication time, shown in Figure \ref{fig:syn-mg-commtime}, \ref{fig:syn-cr-commtime}. sAMG on the other hand benefit from random placement, shown in Figure \ref{fig:syn-samg-commtime}. 

Contiguous placement coupled with minimal routing prevent applications from sharing network resource, and confine application communication traffic to the routers assigned to each application. This can guarantee the performance of less communication intensive applications like MultiGrid and CrystalRouter, and make the communication intensive application like sAMG severely deteriorate. 


\begin{figure*}[t!]
    \centering
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.5 in]{syn-wkld/amg10/commtime}
        \caption{sAMG Communication Time}
        \label{fig:syn-samg-commtime}
    \end{subfigure}%
    \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.5 in]{syn-wkld/mg/commtime}
        \caption{MG Communication Time}
        \label{fig:syn-mg-commtime}
    \end{subfigure}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.5 in]{syn-wkld/cr/commtime}
        \caption{CR Communication Time}
        \label{fig:syn-cr-commtime}
    \end{subfigure}%
   \caption{Application communication time. Three applications running concurrently on dragonfly network with different placement and routing configurations. Random placement and adaptive routing can improves AMG's communication time. MG and CR communication time are prolonged with random placement and adaptive routing.}
   \label{fig:syn-apps-commtime}
\end{figure*}

% explain the network status of sAMG, MG and CR
We look into the network level to scrutinize the traffic go through the routers belongs to each application. 
Figure \ref{fig:syn-samg-lc-traffic}, \ref{fig:syn-samg-gc-traffic} shows the traffic go through the local and global channels of the routers that belongs to sAMG when different placement \& routing configuration in use. The traffic is skyrocketing in both local and global channels when contiguous placement coupled with minimal routing. The contiguous placement make all the MPI ranks of sAMG reside on a set of nodes in the groups that adjacent to each other and minimal routing confines the traffic in those groups, results in severe local congestion. When adaptive routing is used, the local congestion will be alleviated in both local and global channels, as some traffic will be redirected to other part of the network. Random placement scheme can further reduce the traffic burden on local and global channels by assigning each MPI rank of sAMG with randomly select nodes, thus uniformly distribute sAMG traffic over the network. 

MultiGrid become a victim of sAMG's bully when running under random placement. The traffic go through the local and global channels of the routers that belongs to MultiGrid are shown in Figure \ref{fig:syn-mg-lc-traffic}, \ref{fig:syn-mg-gc-traffic}. Although contiguous placement allocates all the MPI ranks in set of nodes in adjacent groups, causing possible local congestion, it will stop MultiGrid's routers being shared by the traffic from its communication-intensive peer, sAMG. As random placement is used, the traffic go through both local and global channels are greatly increased. 

CrystalRouter has more traffic than MultiGrid. The random placement won't redirect much traffic from other applications to the routers belongs to CrystalRouter, compared with contiguous placement, as shown in Figure \ref{fig:syn-cr-lc-traffic}, \ref{fig:syn-cr-gc-traffic}.



\begin{figure*}[t]
    \centering
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.5 in]{syn-wkld/amg10/lc-traffic}
        \caption{sAMG Local Channel Traffic}
        \label{fig:syn-samg-lc-traffic}
    \end{subfigure}\hfill
    \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.5 in]{syn-wkld/mg/lc-traffic}
        \caption{MG Local Channel Traffic}
        \label{fig:syn-mg-lc-traffic}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.5 in]{syn-wkld/cr/lc-traffic}
        \caption{CR Local Channel Traffic}
        \label{fig:syn-cr-lc-traffic}
    \end{subfigure}\\
    \centering
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.5 in]{syn-wkld/amg10/gc-traffic}
        \caption{sAMG Global Channel Traffic}
        \label{fig:syn-samg-gc-traffic}
    \end{subfigure}\hfill
    \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.5 in]{syn-wkld/mg/gc-traffic}
        \caption{MG Global Channel Traffic}
        \label{fig:syn-mg-gc-traffic}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.5 in]{syn-wkld/cr/gc-traffic}
        \caption{CR Global Channel Traffic}
        \label{fig:syn-cr-gc-traffic}
    \end{subfigure}%
   \caption{The traffic go through the local and global channels of routers that belong to specific application.}
   \label{fig:syn-3app-gc-traffic}
\end{figure*}


\subsection{Key Finding}
Our study with synthetic workload confirms that the ``bully" behavior among concurrently running applications would happen when two conditions are satisfied.

\emph{First, the placement \& routing configuration allows network resource sharing between concurrently running applications. Random placement enables the router sharing and adaptive routing enables local and global channel sharing.}

\emph{Second, there are difference in terms of communication intensity between concurrently running applications. In workload \Rmnum{1}, AMG has the least amount of communication traffic compared with MultiGrid and CrystalRouter and it become the ``bullee". In workload \Rmnum{2}, sAMG has the most amount of communication traffic, which makes it the ``bully". }

We can stop this ``bully" by making both conditions invalid. 


\section{Stop the ``Bully"}

The solution for preventing this ``bully" behavior is to avoid network sharing between concurrently running jobs. Using contiguous placement\& minimal routing could be a way avoid network sharing, but both the workload and network performance could suffer degradation due to local congestion. It is also unrealistic to use different routing scheme for each application with regard to its communication intensity, since routing scheme is pre-configured in the system and can not be changed on the fly. However, the job placement can be versatile to assign different allocation (contiguous or random) to specific application.

\begin{figure*}[t!]
    \centering
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.3 in]{hyb-plcmt/amg/commtime}
        \caption{AMG Communication Time}
        \label{fig:hyb-plcmt-amg-commtime}
    \end{subfigure}\hfill
    \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.3 in]{hyb-plcmt/mg/commtime}
        \caption{MG Communication Time}
        \label{fig:hyb-plcmt-mg-commtime}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.3 in]{hyb-plcmt/cr/commtime}
        \caption{CR Communication Time}
        \label{fig:hyb-plcmt-cr-commtime}
    \end{subfigure}%
   \caption{Application communication time. Three applications running concurrently on dragonfly network with different placement\& routing configurations. \textbf{HM, HA, HPA} denote hybrid placement coupled with minimal, adaptive and progressive adaptive routing respectively. }
   \label{fig:hyb-plcmt-apps-commtime}
\end{figure*}

Thus, we propose the hybrid placement as a reconcile solution. In the hybrid placement, the less communication-intensive application will get contiguous allocation while the communication-intensive ones will get random allocation. We evaluate the performance of hybrid placement\&routing configurations with parallel Workload \Rmnum{1}. AMG gets contiguous allocation, MultiGrid and CrystalRouter get random allocation. Figure \ref{fig:hyb-plcmt-apps-commtime} shows each application communication time when hybrid placement coupled with different routing schemes, together with other configurations. 

MultiGrid and CrystalRouter have basically the same performance with hybrid placement compared against random placement. Since they get random allocation in the hybrid placement scheme. AMG being improved a lot when hybrid placement in use. Compared with ``RA" and ``RPA", ``HA" and ``HPA" can significantly reduce AMG communication time, shown in Figure \ref{fig:hyb-plcmt-amg-commtime}. This is due the contiguous allocation AMG gets in the hybrid placement scheme. AMG doesn't share router with other applications. However, when (progressive) adaptive routing are in use, the traffic from MultiGrid and CrystalRouter is still being redirected to the groups where AMG resides. Since AMG is less communication-intensive and can not fully utilize network bandwidth, it is likely that the intermediate routers pick for the traffic from MultiGrid and CrystalRouter are from AMG's group. 





%\section{Summary}
%Based on the results we got from both real application traces and synthetic workload, we can make the following observations:
%
%\begin{itemize}
%    \item Random placement and adaptive routing can uniformly distribute workload traffic over the network, make the whole network load-balanced and hot-spots free. 
%    \item Random placement and adaptive routing can not guarantee QoS for each application in the workload. In order to reach load-balanced and hot-spots free, the traffic from congested routers will be redirected to other less busy routers. This will indulge the ``bully" that communication-intensive applications impose to their less intensive peers. 
%    \item Contiguous placement and minimal routing guarantee a consistent performance of each application. Although, contiguous placement and minimal routing usually results in local congestion and unbalanced network utilization, it can reduce the interference between concurrently running applications, thus prevent less communication-intensive application from being ``bullied" by its communication-intensive peers.
%\end{itemize}


%We believe choosing the ideal placement and routing strategies for workload running on dragonfly network should be based on application's communication intensity. The less intensive applications should avoid sharing network resource with other applications, reduce the possible interference. Contiguous placement and adaptive routing can guarantee the QoS for the less intensive applications, thus prevent the ``bully" from happening. 

%The communication-intensive applications tend to cause local congestion. It is preferable to enable communication-intensive applications to have extra network resource by sharing with other applications.  Random placement and adaptive routing can alleviate the local congestion by redirecting traffic to other less busy routers in the network. 

%So the ideal placement and routing strategies for workload running on dragonfly network should be like this. The communication-intensive applications should be randomly allocated over the system and adaptive routing should be used by these applications to alleviate the local congestion. On the other hand, less intensive application should get contiguous allocation, minimal routing should be used by these applications to avoid network sharing and reduce interference. 
 


\section{Related Work}
\label{sec:related work}

The impact of job placement to both system and application always catch researchers appetite \cite{dskinner} \cite{abhinav-sc13} \cite{jose-ipdps15}. Skinner et al. identified that network congestion could cause significant performance variability \cite{dskinner}. Bhatele et al. studied the performance variability of a specific application, p3FD, running on different production system \cite{abhinav-sc13}. They noticed that the application performance would keep consistent when it got compact allocation and exclusive network resource. Jokanovic et al. studied the impact of job placement to the workload and claimed that the key to reduce performance variability is to avoid network sharing \cite{jose-ipdps15}. 

Recently, several researchers have investigated the job placement and routing schemes on dragonfly network. Bogdan et al. proposed novel solution for mapping tasks of application that conforms to Nearest Neighbor communication pattern on dragonfly network \cite{hoefler-hpdc14}. Jain et al. conducted a comprehensive analysis of various job placement and routing scheme with regard to network link throughput on dragonfly network \cite{jain-sc14}. Their work is based on an analytical model and synthetic workload. Bhatele et al. used simulation to study the performance of synthetic workload under the different task mapping and routing schemes on two-level direct networks \cite{bhatele-sc11}.


Our work different from the previous works in the following ways. First, instead of using synthetic workload that generated based on predefined communication patterns, our simulation is driven by real application traces collected from production system. Second, not only we care about the workload performance, but also we pay attention to each individual application in the workload. We found that although random placement \& adaptive routing can improve the workload performance, some specific application in the workload may suffer performance degradation. Third, with the sophisticated simulation tool CODES, we can not only get applications communication information, but also the insight about the network status when application is running. The traffic and busy time of router's each link are valuable information for detailed analysis.

\section{Conclusion}
\label{sec:conclusion}

In this paper, we have conducted extensive study about application's behavior when running on dragonfly network with different job placement and routing configurations. We resorted to CODES, a high-fidelity HPC network simulation tool, and used three parallel scientific applications traces collected from production system to analysis the applications' behavior on network level. We found that when applications are running concurrently, although random placement can uniformly distribute the workload traffic over the network to reach load balance and hot-spots free for the network, the performance of certain application would be impaired. We identify this phenomenon as ``bully" between concurrently running applications, and the victim always being the less communication-intensive one. On the other hand, the contiguous placement tend to cause local congestion, however when coupled with adaptive routing, the configuration can guarantee the performance of ``bullee" application by limiting the network sharing between concurrently running peers. 

Due the presence of this ``bully", we suggest that when the batch scheduler make job placement for workload on dragonfly system, random placement shouldn't be the rule of thumb. Instead, the placement should made with consideration of jobs communication intensity. The less intensive application should get contiguous allocation coupled with adaptive routing, the intensive ones should get random allocation coupled with minimal routing. We believe the findings presented in this paper can illuminate a path to more efficient workload manager for future systems with dragonfly network.



% conference papers do not normally have an appendix



% use section* for acknowledgment
\ifCLASSOPTIONcompsoc
  % The Computer Society usually uses the plural form
  \section*{Acknowledgments}
\else
  % regular IEEE prefers the singular form
%   \section*{Acknowledgment}
\fi


The work at Illinois Institute of Technology is supported in part by U.S. National Science Foundation grants CNS-1320125 and CCF-1422009. This work is also supported by the U.S. Department of Energy, Office of Science, Advanced Scientific Computing Research, under Contract DE-AC02-06CH11357.


% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{4}


\bibliographystyle{IEEEtran}
\bibliography{./reference}  


 \vspace{1\baselineskip}
 
 \begin{framed}
 The submitted manuscript has been created by UChicago Argonne, LLC, Operator of Argonne National Laboratory ("Argonne").  Argonne, a U.S. Department of Energy Office of Science laboratory, is operated under Contract No. DE-AC02-06CH11357.  The U.S. Government retains for itself, and others acting on its behalf, a paid-up nonexclusive, irrevocable worldwide license in said article to reproduce, prepare derivative works, distribute copies to the public, and perform publicly and display publicly, by or on behalf of the Government.
 \end{framed}




% that's all folks
\end{document}


