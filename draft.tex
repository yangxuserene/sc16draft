%% bare_conf_compsoc.tex
%% V1.4b
%% 2015/08/26
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8b or later) with an IEEE Computer
%% Society conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/pkg/ieeetran
%% and
%% http://www.ieee.org/

\documentclass[conference,compsoc]{IEEEtran}
% Some/most Computer Society conferences require the compsoc mode option,
% but others may want the standard conference format.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference,compsoc]{../sty/IEEEtran}

% *** MISC UTILITY PACKAGES ***
%
\usepackage{ifpdf}
\usepackage{framed}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/pkg/ifpdf
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.



% *** CITATION PACKAGES ***
%
\ifCLASSOPTIONcompsoc
  % IEEE Computer Society needs nocompress option
  % requires cite.sty v4.0 or later (November 2003)
  \usepackage[nocompress]{cite}
\else
  % normal IEEE
  \usepackage{cite}
\fi



% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/pkg/graphicx
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/pkg/epslatex
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). The IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
\usepackage{amsmath}
\usepackage{cuted}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics.
%
% Note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/amsmath
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}




% *** SPECIALIZED LIST PACKAGES ***
%
\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as the IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/pkg/algorithms
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/pkg/algorithmicx




% *** ALIGNMENT PACKAGES ***
%
\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/array


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=footnotesize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a sans serif font rather
% than the serif font used in traditional IEEE formatting and thus the need
% to invoke different subfig.sty package options depending on whether
% compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/pkg/subfig
\usepackage{verbatim}
\usepackage{soul}
\usepackage{xcolor}
\newcommand{\TODO}[1]{\hl{TODO: #1}}
\newcommand{\NOTE}[1]{\hl {NOTE: #1}}
\newcommand{\changed}[1]{\textcolor{red}{#1}}


% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure.
% Be aware that LaTeX2e kernels dated 2015 and later have fixltx2e.sty's
% corrections already built into the system in which case a warning will
% be issued if an attempt is made to load fixltx2e.sty as it is no longer
% needed.
% The latest version and documentation can be found at:
% http://www.ctan.org/pkg/fixltx2e


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/stfloats
% Do not use the stfloats baselinefloat ability as the IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that the IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as the IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
% \usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/pkg/dblfloatfix




% *** PDF, URL AND HYPERLINK PACKAGES ***
%
\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/url
% Basically, \url{my_url_here}.

\usepackage{graphicx} % Required for including pictures
\graphicspath{{pics/}} % Specifies the directory where pictures are stored
\usepackage{caption}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{multirow} % make table

\makeatletter % Put Roman Number in Text
\newcommand{\rmnum}[1]{\romannumeral #1}
\newcommand{\Rmnum}[1]{\expandafter\@slowromancap\romannumeral #1@}
\makeatother



% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{Watch Out for the Bully! Study of Interference Between Jobs Running Concurrently on Dragonfly Network}


% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
% \author{\IEEEauthorblockN{Michael Shell}
% \IEEEauthorblockA{School of Electrical and\\Computer Engineering\\
% Georgia Institute of Technology\\
% Atlanta, Georgia 30332--0250\\
% Email: http://www.michaelshell.org/contact.html}
% \and
% \IEEEauthorblockN{Homer Simpson}
% \IEEEauthorblockA{Twentieth Century Fox\\
% Springfield, USA\\
% Email: homer@thesimpsons.com}
% \and
% \IEEEauthorblockN{James Kirk\\ and Montgomery Scott}
% \IEEEauthorblockA{Starfleet Academy\\
% San Francisco, California 96678-2391\\
% Telephone: (800) 555--1212\\
% Fax: (888) 555--1212}}


\author{

\IEEEauthorblockN{Xu Yang\IEEEauthorrefmark{1}, John Jenkins\IEEEauthorrefmark{2}, Misbah Mubarak\IEEEauthorrefmark{2}, Robert B. Ross\IEEEauthorrefmark{2}, Zhiling Lan\IEEEauthorrefmark{1}}

\IEEEauthorblockA{\IEEEauthorrefmark{1}Department of Computer Science,
Illinois Institute of Technology,
Chicago, Illinois, USA 60616\\
\{xyang56\}@hawk.iit.edu, lan@iit.edu}

\IEEEauthorblockA{\IEEEauthorrefmark{2}Mathematics and Computer Science Division, Argonne National Laboratory,
Argonne, IL, USA 60439\\
\{jenkins,rross\}@mcs.anl.gov, mmubarak@anl.gov}
}


% conference papers do not typically use \thanks and this command
% is locked out in conference mode. If really needed, such as for
% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
% after \documentclass

% for over three affiliations, or if they all won't fit within the width
% of the page (and note that there is less available width in this regard for
% compsoc conferences compared to traditional conferences), use this
% alternative format:
% 
%\author{\IEEEauthorblockN{Michael Shell\IEEEauthorrefmark{1},
%Homer Simpson\IEEEauthorrefmark{2},
%James Kirk\IEEEauthorrefmark{3}, 
%Montgomery Scott\IEEEauthorrefmark{3} and
%Eldon Tyrell\IEEEauthorrefmark{4}}
%\IEEEauthorblockA{\IEEEauthorrefmark{1}School of Electrical and Computer Engineering\\
%Georgia Institute of Technology,
%Atlanta, Georgia 30332--0250\\ Email: see http://www.michaelshell.org/contact.html}
%\IEEEauthorblockA{\IEEEauthorrefmark{2}Twentieth Century Fox, Springfield, USA\\
%Email: homer@thesimpsons.com}
%\IEEEauthorblockA{\IEEEauthorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212, Fax: (888) 555--1212}
%\IEEEauthorblockA{\IEEEauthorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}




% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract
\begin{abstract}

The high-radix, low-diameter dragonfly topology network will be the choice of many computing facilities for building their next generation supercomputers. Preliminary study shows that random placement with adaptive routing should be the rule of thumb to utilize such powerful network, since random placement can uniformly distribut traffic over the network, and adaptive routing can alleviate congestion. However, in this paper, we made the observation that although random placement coupled with adaptive routing can reach load-balanced over the network when multiple jobs running concurrently, it can not guarantee the best performance for each single job. The performance improvement of communication intensive jobs comes with sacrifice of those less intensive jobs. We refer this phenomenon as ``bully" between concurrently running jobs. We analyze the detailed reason behind this ``bully" behavior between jobs from the underneath network level. Our study is based on a sophisticated, high-fidelity discrete even-driven simulation tool. We believe the observations and analysis in this work will make the chosen of job placement and routing strategies on dragonfly network more cautiously in future.


\end{abstract}

% no keywords

% \keywords{Dragonfly, Job placement, Routing, Interference}



% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}
\label{sec:intro}

The low latency and high bandwidth interconnect network plays a critical role in improving HPC system performance. As the computing ability continue grows due to many-core nodes with accelerators, the network is now becoming a scare resources. HPC community start to explore the possible alternative to replace the commonly used Torus network.

The high-radix, low-diameter dragonfly topology can lower the cost of interconnect network, improve network bandwidth, reduce the packets traverse latency. This make the dragonfly network an very promising choice for building multi-Petaflop/s supercomputers\cite{dally-dragonfly}. The procurement results from Trinity and CORAL project shows the great performance improvement can be got from using dragonfly network. 


Even with such powerful network, the interference between concurrently running jobs and thus presumably job placement remains an major factor cause performance variability on dragonfly network\cite{bhatele2015, dskinner}. Some research work suggest that random job placement coupled with adaptive routing can alleviate local congestion, eliminate hot-spots and reach load-balance for dragonfly networks \cite{jain-sc14, bhatele-sc11, brandt2014}. 

This is paper, we study the interference between concurrently running jobs on dragonfly network with different job placement and routing schemes. Being unorthodox to most existing work that use synthetic workload, parallel scientific application traces that collected from production system are used in our study. The advantage of using real application traces is quite obvious, these traces can capture application's communication behavior in detail that usually omitted in synthetic workload for the purpose of simplicity. Applicatoins usually are distinctive from each other in terms of  data transfer amount, communication pattern, operation dependency etc. which are impossible to reproduce in synthetic workload.


%We also evaluate the network performance and jobs' performance when the Dragonfly network is configured with different job allocation strategies and routing algorithms. The job allocation strategies used in our study are Compact allocation and Random allocation, both of which can be seen in existing production HPC systems. The routing strategies been analyzed in this work are Minimal, Nonminimal and Adaptive.  


We made observation from our extensive study that, when dragonfly network is configured with random placement and adaptive routing scheme in order to reach hot-spots free and load balance, the performance of particular job(s) in the workload would suffer degradation. The communication intensive jobs in the workload can benefit from random placement and adaptive routing, with great performance improvement. Unfortunately, those less intensive jobs are the sacrifices for this improvement, their performance will be greatly reduced. We identify this phenomenon as ``bully" between concurrently running jobs.

The findings in this work also reconfirm that interference between concurrently running jobs would make the performance of some jobs very unpredictable. The detailed analysis about the traffic and congestion in network level unveil the undercurrent beneath that interference. This work makes the following contributions:

\begin{itemize}
   
    \item Our real trace-based analysis about job interference on dragonfly network, shows that random placement with adaptive routing can not guarantee the performance of every job in the workload. The hot-spots free and load-balanced reached by using random placement with adaptive routing come with the cost of less communication-intensive jobs performance degradation. 

    \item We identify the ``bully" behavior happening between concurrently running jobs on dragonfly network when random placement and adaptive routing in use. Random placement and adaptive routing redirect the traffic of communication intensive jobs to the routers through which less intensive jobs' traffic used to go, embezzle the network resource such as local and global channel bandwidth, slow down the communication of those less intensive jobs.

    
    \item We found that contiguous placement and minimal routing can guarantee the consistent performance of each job running on dragonfly network, while may result in hot-spots and local network congestion. Actually, contiguous placement and minimal routing are preferred by communication-less-intensive jobs, since it will prevent them from being ``bullied" by other communication-intensive jobs.
    
         
\end{itemize}

To the best of our knowledge, using parallel application traces from production system for the study of job interference on dragonfly network has not been reported so far. We believe the observations and analysis presented in this paper can be used by computing facilities to choose job placement and routing strategies wisely for their future dragonfly interconnected system. The conclusion from this paper would be useful for workload manager in dragonfly system to make better scheduling decisions for jobs with distinctive communication behavior.

\section{Background}
\label{sec:background}
The dragonfly network is promising alternative for connecting a large number of nodes for its high-radix and low-diameter topology\cite{dally-dragonfly} \cite{kim-micro} \cite{faanes}. However, even with such powerful network, the job placement and routing could still be important factor that impact application's performance. 


\subsection{Dragonfly Network Overview}
\label{sec:network}
The dragonfly is a two-level hierarchical topology. It consists of several groups connected by All-to-All links. In each group, there could be ``a" number of routers connected via All-to-All local channels. For each router, there could be ``p" number of compute nodes attached to it via terminal links. The router has ``h" number of global channels that used as intergroup connections through which the router connected to other routers in different groups. Thus, the radix of each router is $k = a+h+p-1$. The implementation of such dragonfly network could be different between different computing facilities. The choosing of proper $a$, $h$, $p$ could be involving many factors, such as system scale, building cost and workload requirements. 

For the purpose of loading balance, it is recommended that the proper dragonfly configuration should be like $a=2p=2h$\cite{kim-micro}. Under this configuration, the total number of groups ``g" in the dragonfly network would be $g = a*h+1 $, the total number of compute nodes ``N" in the network would be $N = p*a*g $. Figure \ref{fig:dragonfly overview} illustrated an implementation of dragonfly network follows such configuration. There are 6 routers in each group, each router has 3 compute nodes attached to it. This dragonfly implementation consists of 19 groups and 342 nodes in total.

\begin{figure}[h!] 
  \centering
  \includegraphics[width=0.48\textwidth]{dragonfly-overview}
  \caption{Dragonfly Network Overview. Illustration of part of dragonfly network. There are 19 groups, 6 routers in each group, 3 compute nodes connected to each router, 342 nodes in total. Job\_1 requires for 6 nodes, get the allocation by Random placement. Job\_2 requires for 8 nodes, get the allocation by Contiguous placement. }
  \label{fig:dragonfly overview}
\end{figure}


\subsection{Job Placement}
\label{sec:placement-routing}

Job placement refers to the scheme used by batch scheduler to allocate the required number of nodes by each job for execution. As studied by several researchers, the job placement could be an important factor that impact application performance \cite{hoefler-hpdc14} \cite{bhatele-sc11} \cite{jain-sc14}. In this work, we study the following two placement schemes that are most likely to be deployed in the future dragonfly system.

\textbf{Contiguous Placement:} In this scheme, the nodes will first be indexed consecutively in an increasing order of their group id and router id. The schedul assign each job required number of nodes by cutting chunks of nodes from the sequentially ordered list, as illustrated in Figure \ref{fig: dragonfly overview} as blue nodes assigned to job\_2. The nodes been allocated to the same job will be adjacent to each other, usually they are attached to the same router or in the same group, depends on the size of the job. Contiguous placement confines the traffic of application into the local area, which may result in local network congestion and increase the possibility of hot-spots. 

\textbf{Random Placement:} In this scheme, job will get a set of nodes that randomly selected from all the available nodes in the system. The nodes allocated to each job would be attached to different routers in different groups, as illustrated in Figure \ref{fig: dragonfly overview} the red nodes assigned to job\_1. Some routers may be shared by different applications when using random placement. Random placement can spreading the traffic of application uniformly across the whole system, thus avoid the possible local congestion and reach load balance.


\subsection{Routing Schemes}
\label{sec:routing}

The implemented routing schemes in CODES dragonfly network model are based on the routing algorithm proposed by Kim et al. \cite{dally-dragonfly} and Jiang et al. \cite{jiang}. Three routing schemes are studied in this work are \emph{Minimal}, \emph{Adaptive} and \emph{Progressive Adaptive}.

\textbf{Minimal:} When the network deploy minimal routing, a message from source router will take the the shortest path to the destination router. When there are multiple shortest paths between the rource and destination router, the message will be evenly divided among the paths. Minimal routing can guarantee the minimum hops the message takes from source to destination. However, it may result in congestion along the shortest path. 


\textbf{Adaptive:} In this scheme, the path a message takes will be adaptively chosen between shortest and non-shortest path, depends on the congestion situation along that path. For the non-shortest path, an intermediate router will be randomly chosen. The message will first take the shortest path from source to that intermediate router, then it will take the shortest path from that intermediate router to the destination. Since adaptive scheme chooses routing path adaptively based on the congestion situation, it can void local congestion and reduce the possibility of hot-spots. 

\textbf{Progressive Adaptive:} In this scheme, the decision to route minimally at each hop in the source group will be re-evaluated and any decision to route non-minimally at source router or at a subsequent hop is permant and is not re-evaluated \cite{jiang}. The progressive adaptive is capable of handling the case where a global link is congested but this information has not yet propagated back to the source router \cite{jiang}. The packet will take the non-minimal route only when the congestion is encountered. 



\section{Methodology}
\label{sec: methodology}

It is difficult to do experiment with concurrently running jobs on HPC system. One reason is that job placement and routing strategy are part of system configuration, it is impossible for user to make changes at will. Another reason is that it is unrealistic to reserve the system exclusively to run the same batch of jobs with desired placement and routing configurations and compare the results. Therefore, we resort to simulation in our work.

\subsection{Simulation Tool}
A simulation toolkit named CODES, Co-Design of Multilayer Exascale Storage Architectures, enables the exploration of simulating different HPC networks with high fidelity and great scalability\cite{codes}.  CODES supports dragonfly network with packet-level high-fidelity simulation\cite{codes-dragonfly}. It has this network workload component that is capable of taking real MPI application traces generated by SST DUMPI\cite{sst} for trace-driven simulations.

\subsection{Application Traces}
\label{sec: application traces}

We choose three representative parallel applications from DOE Design Forward Project\cite{designforwardwebpage}. We believe these applications can be representative of a wide array of applications running on leadership-class supercomputers. Specifically, we study the Algebraic MultiGrid Solver (AMG), Geometric MultiGrid (MultiGrid) and CrystalRouter MiniApps. 

AMG: The Algebraic MultiGrid Solver, is a parallel algebraic multi-grid solver for linear systems arising from problems on unstructured mesh physics packages. It has been derived directly from the BoomerAMG solver that is being developed in the Center for Applied Scientific Computing (CASC) at LLNL\cite{amg}. 
% The traces of AMG we chosen are comprised of 216 MPI ranks.

MultiGrid:  geometric multi-grid v-cycle from the production elliptic solver BoxLib, a software framework for massively parallel block-structured adaptive mesh refinement (AMR) codes\cite{boxlib}. It is widely used for structured grid physics packages. 
% The traces of MultiGrid we chosen are comprised of 125 MPI ranks.

CrystalRouter: the extracted communication kernel of the full application Nek5000\cite{nek5000}, which is a spectral element CFD application developed at Argonne National Laboratory\cite{crystalrouter}. It features spectral element multi-grid solvers coupled with a highly scalable, parallel coarse-grid solver that is widely used for projects including ocean current modeling, thermal hydraulics of reactor cores,and spatiotemporal chaos. 
% The traces of CrystalRouter we chosen are comprised of 100 MPI ranks.



\subsection{Simulation Configuration}
\label{sec: simulation configuration}


\begin{table}[ht]
\begin{center}
\caption{The notation for different placement \& routing configurations} 
\label{tab: placement routing configs}
%\centering % Centers the table on the page, comment out to left-justify
\begin{tabular}{l c c c }
\toprule % Top horizontal line
\toprule
&\multicolumn{3}{c}{Routing} \\ % Amalgamating several columns into one cell is done using the \multicolumn command as seen on this line
\cmidrule(l){2-4}
Placement  & Minimal & Adaptive & Progressive adaptive\\ % Column names row
\midrule % In-table horizontal line
Contiguous  &  CM   &   CA   &  CPA   \\ % Content row 1
\midrule
Random  &   RM  &   RA   &  RPA   \\ 

\midrule % In-table horizontal line
\bottomrule % Bottom horizontal line
\end{tabular}
\end{center}
\end{table}

The dragonfly network studied in this work consists of 33 groups, each group contains 8 routers and each router has 4 compute nodes attached to it. Overall, there are 264 routers and 1056 compute nodes in the network. The bandwidth of both terminal links and local channel are set to 2GB/s, the global channel bandwidth is set to 4GB/s. 

We focus on the study of two placement schemes and three routing schemes, so there will be 6 different placement\&routing configurations, as listed in Table \ref{tab: placement routing configs}. In this work, we enable the applications running on dragonfly network under different placement and routing configurations, and scrutinize the application's performance and network behavior in different running scenarios. 

In our experiments, the workload running on the dragonfly network under 6 different placement and routing configurations as listed in Table \ref{tab: placement routing configs}. We focus on the analysis of network status while the workload is running, as well as the performance of each individual application. We collected the following result data from the experiments:

\begin{itemize}
    \item router terminal link traffic and busy time.
    \item router local channel traffic and busy time.
    \item router global channel traffic and busy time.
    \item The time spend on communication for each MPI rank. 
\end{itemize}

The results of random placement shown in the following experiments are collected from extensive runs of different random placements, which can eliminate the possibility of variations.

\section{Parallel Workload \Rmnum{1 }}
\label{sec: workload 1 overview}

The first parallel workload analyzed in our experiment consists of three applications presented in section\ref{sec: application traces} . The details of this workload shown in Table \ref{tab: parallel workload-1}.

\begin{table}[ht]
\begin{center}
\caption{Details of Parallel Workload \Rmnum{1 }.} 
\label{tab: parallel workload-1}
%\centering % Centers the table on the page, comment out to left-justify
\begin{tabular}{l c c c }
\toprule % Top horizontal line
\toprule
&\multicolumn{3}{c}{Application Details} \\ % Amalgamating several columns into one cell is done using the \multicolumn command as seen on this line
\cmidrule(l){2-4}
App Name & num. rank & Data per Rank & Total Data\\ % Column names row
\midrule % In-table horizontal line
AMG  &    216 &   0.6MB   &     130MB\\ % Content row 1
\midrule
MultiGrid  &    125 &   5MB   &     625MB\\ 
\midrule
CrystalRouter  &   100  &  35MB    &     3500MB\\ 

\midrule % In-table horizontal line
\bottomrule % Bottom horizontal line
\end{tabular}
\end{center}
\end{table}


\begin{figure}[h!]
  \centering
  \includegraphics[width = 0.48\textwidth ]{data_amount}
  \caption{Applications Data Transfer Amount. AMG has the least amount of data transfer, compared with CR and MG.}
  \label{fig:3app-data-amount}
\end{figure}

Figure \ref{fig:3app-data-amount} shows the data transfer amount of each MPI rank of three application. Based on this figure, we can tell that CrystalRouter is the most communication-intensive and AMG is the lest communication-intensive. 

\subsection{Workload Analysis}
\begin{figure}[h!]
  \centering
  \includegraphics[width = 0.48\textwidth ]{wkld/wkld-commtime}
  \caption{Time spent on communication by Workload I when 6 different placement and routing configurations are used. Random is better than contiguous in terms of improving communication efficiency.Communication time can be further reduced when (progressive) adaptive routing is used under both placement schemes. }
  \label{fig:wkld-commtime}
\end{figure}

The communication time spent by parallel workload \Rmnum{1} under different placement and routing configuration shown in Figure \ref{fig:wkld-commtime}. The contiguous placement coupled with minimal routing results in highest communication time. The random placement coupled with minimal routing is the most efficient. Progressive adaptive routing is basically the same as adaptive when coupled with both placement schemes.


\begin{figure*}[t!]
    \centering
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{wkld/gc-traffic}
        \caption{Global Channel Traffic}
        \label{fig:global-channel-traffic}
    \end{subfigure}%
    \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{wkld/lc-traffic}
        \caption{Local Channel Traffic}
        \label{fig:local-channel-traffic}
    \end{subfigure}%
    \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{wkld/tl-traffic}
        \caption{Terminal Link Traffic}
        \label{fig:terminal-link-traffic}
    \end{subfigure}%
  \caption{Network Traffic. \textbf{More explanation to be added for this figure}}
   \label{fig:wkld-network-traffic}
\end{figure*}

\begin{figure*}[t!]
    \centering   
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{wkld/gc-stime}
        \caption{Global Channel Busy Time}
        \label{fig:global-channel-stime}
    \end{subfigure}%
     \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{wkld/lc-stime}
        \caption{Local Channel Busy Time}
        \label{fig:local-channel-stime}
    \end{subfigure}%
    \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{wkld/tl-stime}
        \caption{Terminal Link Busy Time}
        \label{fig:terminal-link-stime}
    \end{subfigure}%
   \caption{Network Channel Busy Time. \textbf{More explanation to be added for this figure}}
   \label{fig:wkld-network-stime}
\end{figure*}


Figure \ref{fig:wkld-network-traffic} shows the amount of traffic go through terminal links, local channels and global channels when the workload running on dragonfly network with 6 different placement and routing configurations, and Figure \ref{fig:wkld-network-stime} shows the corresponding busy time. 

%global link traffic and busy time explanation
When the workload is running with contiguous placement and minimal routing, all the MPI ranks are physically adjacent to each other, and the packets are routed through the shortest path between its source rank to destination rank. In this case, all the traffic are on the first half of the network (node id from 0 to $216+125+100-1=440$, group id from 0 to 13 ), causing the network local congestion and traffic load on some routers are extremely high, as shown the blue dash line in Figure \ref{fig:global-channel-traffic}. Thus the busy time of global channel is also the highest when contiguous placement coupled with minimal routing, as shown in Figure \ref{fig:global-channel-stime} the blue dash line. 

When contiguous placement is coupled with adaptive routing or progressive adaptive routing, the local congestion on global channel will be greatly alleviated, as shown in Figure \ref{fig:global-channel-traffic} the red and green dash line. Since both adaptive and progressive adaptive routing are congestion aware, and be able to utilize the idle routers on the other part of the network. The busy time of global channel are also reduce by using contiguous placement coupled with either adaptive or progressive adaptive routing, as shown in Figure \ref{fig:global-channel-stime} the red and green dash line. 

Random placement can randomly allocate the MPI ranks to the physical nodes all over the network, thus prevent the traffic from being congested certain part of the network. Shown as the solid lines in Figure \ref{fig:global-channel-traffic}, the traffic go through global channels are quite uniformly distributed across all the routers in the network, thus no particular global channel will suffer high traffic burden. When the random placement coupled with minimal routing, the packets can avoid unnecessary intermediate forwarding as introduced by adaptive and progressive routing, which results in generating less traffic. That's why the blue solid line is lower than the red and green solid line, shown in figure\ref{fig:global-channel-traffic}. Since the random placement can uniformly distribute the workload traffic, there are no sudden surge of busy time of global channel over the network, shown as solid lines in Fgiure \ref{fig:global-channel-stime}.

%local channel traffic and busy time explanation

We can get the same observation from the local channel traffic (Figure \ref{fig:local-channel-traffic}) and busy time (Figure \ref{fig:local-channel-stime}). Contiguous placement coupled with minimal routing results in local congestion, thus highest traffic amount on the local channel of certain routers. Even with adaptive or progressive adaptive routing, the local congestion caused by grouping MPI rank on adjacent nodes in contiguous placement can not be eliminated. The random placement can reduce the congestion on local channel for allocating MPI ranks to random selected nodes. 

%terminal link traffic and busy time explanation
The distribution of traffic go through terminal links stay unchanged no matter which placement and routing configuration are used, as shown in Figure \ref{fig:terminal-link-traffic}. This is because only the location of each MPI rank in the network will be changed in different placement schemes, and the routing won't have effect the terminal link, so the traffic between compute node and the router won't change. Due to the traffic changes on global and local channels, the busy time of terminal links will also experience some variation when different placement and routing scheme configuration in use, as shown in Figure \ref{fig:terminal-link-stime}. 


 
% \NOTE{The take-home message} from Figure \ref{fig:wkld-network-stime} and \ref{fig:wkld-network-traffic}. 

Contiguous placement allocates MPI ranks to physical nodes that are adjacent to each other, which confines the workload traffic to some local area when coupled with minimal routing. This may leads to hot-spot in local area and unbalanced network utilization. As we can see from Figure \ref{fig:wkld-network-traffic} and \ref{fig:wkld-network-stime}, contiguous placement coupled with minimal routing always leads to the extreme high traffic amount for some routers , and thus longest busy time.

Random placement allocates MPI ranks to a set of randomly selected nodes all over the system, which will uniformly distribute workload traffic and avoid local congestion. When random placement is coupled with minimal routing, the packets will take the shortest path from source router to the destination router without routing to any intermediate routers, this will prevent the routing from generating extra traffic. When random placement is coupled with adaptive or progressive adaptive routing, the possibility of any congestion will be further reduced at the cost of extra intermediate traffic. 


% Start from here, we present the individual application analysis.
The random job placement coupled with either minimal or adaptive routing can reach hot-spots free and load-balanced by distributing the workload traffic over the network. The workload performance get greatly improved with these configurations. However, when we isolated individual application from the workload, we unveil the fact that not every application can benefit from random job placement. 


\subsection{Individual Application Analysis}

\begin{figure*}[t!]
    \centering
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.5 in]{amg/commtime}
        \caption{AMG Communication Time}
        \label{fig:amg-commtime}
    \end{subfigure}%
    \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.5 in]{mg/commtime}
        \caption{MG Communication Time}
        \label{fig:mg-commtime}
    \end{subfigure}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.5 in]{cr/commtime}
        \caption{CR Communication Time}
        \label{fig:cr-commtime}
    \end{subfigure}%
   \caption{Application communication time. Three applications running concurrently on dragonfly network with different placement and routing configurations. Random placement and adaptive routing can improve MG and CR communication, however, AMG's communication time is greatly prolonged.}
   \label{fig:apps-commtime}
\end{figure*}

Figure \ref{fig:apps-commtime} shows the communication time of three applications running concurrently under 6 different placement and routing configurations listed in Table\ref{tab: placement routing configs}.

As shown in Figure \ref{fig:mg-commtime} \ref{fig:cr-commtime}, MG and CR suffer the longest communication time when running under the configuration of contiguous placement and minimal routing(CM). When contiguous placement coupled with adaptive or progressive adaptive routing, both MultiGrid and CrystalRouter will get great improvement in terms of communication efficiency. Random placement will further reduce the communication time of MultiGrid and CrystalRouter, and reach the best performance when coupled with (progressive) adaptive routing. Both MultiGrid and CrystalRouter shows the same trend as the workload when running under different placement and routing configurations. 

However, AMG is quite an exception. As shown in Figure \ref{fig:amg-commtime}, the communication time of AMG is skyrocketing when it running under random placement coupled with (progressive) adaptive routing. The contiguous placement coupled with (progressive) adaptive routing can reach the best performance for AMG. The performance of AMG running under contiguous placement coupled with minimal routing is no better than random coupled with minimal routing, but still much better than random with (progressive) adaptive routing. 




\begin{figure*}[t!]
    \centering
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{amg/lc-traffic}
        \caption{AMG Local Channel Traffic}
        \label{fig:amg-lc-traffic}
    \end{subfigure}%
    \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{mg/lc-traffic}
        \caption{MG Local Channel Traffic}
        \label{fig:mg-lc-traffic}
    \end{subfigure}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{cr/lc-traffic}
        \caption{CR Local Channel Traffic}
        \label{fig:cr-lc-traffic}
    \end{subfigure}%
   \caption{Each Application Router Local Channel Traffic.  }
   \label{fig:3app-lc-traffic}
\end{figure*}


\begin{figure*}[t!]
    \centering
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{amg/gc-traffic}
        \caption{AMG Global Channel Traffic}
        \label{fig:amg-gc-traffic}
    \end{subfigure}%
    \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{mg/gc-traffic}
        \caption{MG Global Channel Traffic}
        \label{fig:mg-gc-traffic}
    \end{subfigure}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{cr/gc-traffic}
        \caption{CR Global Channel Traffic}
        \label{fig:cr-gc-traffic}
    \end{subfigure}%
   \caption{Each Application Router Global Channel Traffic.}
   \label{fig:3app-gl-traffic}
\end{figure*}

% Show the evidence from network level, explain why AMG is different. 
We look into network level to identify the major culprit behind AMG's abnormal behavior with random placement and adaptive routing. By identifying the terminal nodes and routers that each application's traffic go through, we can see that the traffic amount go through the routers that belongs to AMG is skyrocketing when it running with random placement and adaptive routing, shown in Figure \ref{fig:amg-lc-traffic} and Figure \ref{fig:amg-gc-traffic}. Adaptive routing will redirect the traffic of other applications to go through the routers belongs to AMG, and increase the traffic burden on those routers, thus slow down the communication of AMG.

No router will be shared between applications under contiguous placement. A set of successive groups will be allocated to each application under contiguous placement scheme. When contiguous placement coupled with minimal routing, application will be free of interference from its running neighbors. However, application communication traffic will be confined within their allocated routers, thus local congestion is very likely to happen depends on application communication intensity. As the lest communication intensive application, AMG can benefit from contiguous placement. Under contiguous placement, the traffic go through the local and global channels of the routers that belongs to AMG is significantly lower than random placement, shown in Figure \ref{fig:amg-lc-traffic}, \ref{fig:amg-gc-traffic}. MultiGrid and CrystalRouter are more communication intensive compared with AMG. They will suffer great amount local traffic in both local and global channels when contiguous placement is used, shown as the dash line in Figure \ref{fig:mg-lc-traffic}, \ref{fig:mg-gc-traffic} and Figure \ref{fig:cr-lc-traffic}, \ref{fig:cr-gc-traffic}. The random placement scheme can uniformly distribute their traffic all over the network by allocating randomly selected nodes to each MPI rank. 

The reason for AMG being the only victim from random placement and adaptive routing is due to  its relatively small amount of data transfer, that make it the least communication-intensive application in the workload.

From the detailed analysis of three applications performance above, we know that random placement and adaptive routing is quite efficient for orchestrate the traffic load in the network. Random placement and adaptive routing can uniformly distribute the workload traffic all over the network, make the load-balanced and avoid hot-spots. However, application like AMG will be impaired in this orchestration. The routers through which the less communication-intensive application traffic used to route, now have more traffic go through them. These extra traffic are from other communication-intensive applications. Beneath the facade of harmony, less communication-intensive application are ``bullied" by their communication-intensive peers in the workload. 

We have tried three different congestion sensing schemes that used in adaptive routing\cite{won-prog-adaptive}, although there are some variations of the experiments, none of the congestion sensing scheme can prevent the ``bully" from happening.

\section{Parallel Workload \Rmnum{2 }}

\begin{table}[ht]
\begin{center}
\caption{Details of Parallel Workload \Rmnum{2 }.} 
\label{tab: parallel workload-2}
%\centering % Centers the table on the page, comment out to left-justify
\begin{tabular}{l c c c }
\toprule % Top horizontal line
\toprule
&\multicolumn{3}{c}{Application Details} \\ % Amalgamating several columns into one cell is done using the \multicolumn command as seen on this line
\cmidrule(l){2-4}
App Name & num. rank & Data per Rank & Total Data\\ % Column names row
\midrule % In-table horizontal line
sAMG  &    216 &   60MB   &     13000MB\\ % Content row 1
\midrule
MultiGrid  &    125 &   5MB   &     625MB\\ 
\midrule
CrystalRouter  &   100  &  35MB    &     3500MB\\ 

\midrule % In-table horizontal line
\bottomrule % Bottom horizontal line
\end{tabular}
\end{center}
\end{table}


\begin{figure}[h!]
  \centering
  \includegraphics[width = 0.48\textwidth ]{syn-wkld/data_amount}
  \caption{Applications Data Transfer Amount. sAMG has the most amount of data transfer, compared with CR and MG.}
  \label{fig:syn-3app-data-amount}
\end{figure}

In order to prove that AMG being bullied only because it is less communication-intensive than its running peers, we generate a synthetic application, sAMG, which are same the with AMG's original traces in every aspect expect that the data transfer amount 100x greater than AMG. We run the new workload that consists of sAMG, MultiGrid and CrystalRouter on the same dragonfly network with 6 different placement and routing configurations. As shown in Figure \ref{fig:syn-3app-data-amount}, sAMG become the most communication-intensive application in the new workload. 

\subsection{Workload Analysis}

\begin{figure}[h!]
  \centering
  \includegraphics[width = 0.48\textwidth ]{syn-wkld/wkld-commtime}
  \caption{ Time spent on communication by Workload II when 6 different placement and routing scheme configurations are used. Random is better than contiguous in terms of improving communication efficiency.Communication time can be further reduced when (progressive) adaptive routing is used under both placement schemes. }
  \label{fig:syn-wkld-commtime}
\end{figure}

The communication time spent by parallel workload \Rmnum{2} under different placement and routing configuration shown in Figure \ref{fig:syn-wkld-commtime}. As the data transfer amount increased in the workload(due to sAMG), the time spent on communication under each configuration also increases. But the performance of each configuration still keep the same trend as parallwl workload \Rmnum{1}. The contiguous placement coupled with minimal routing results in highest communication time. The random placement coupled with minimal routing is the most efficient. Progressive adaptive routing is better than adaptive when random placement is used. And they have comparable results when contiguous placement is used. 


\\ \TODO{Explain Figure }  \ref{fig:synwkld-network-traffic} \ref{fig:synwkld-network-stime} 


\begin{figure*}[t!]
    \centering
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{syn-wkld/gc-traffic}
        \caption{Global Channel Traffic}
        \label{fig:synwkld-global-channel-traffic}
    \end{subfigure}%
    \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{syn-wkld/lc-traffic}
        \caption{Local Channel Traffic}
        \label{fig:synwkld-local-channel-traffic}
    \end{subfigure}%
    \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{syn-wkld/tl-traffic}
        \caption{Terminal Link Traffic}
        \label{fig:synwkld-terminal-link-traffic}
    \end{subfigure}%
  \caption{Network Traffic. \textbf{More explanation to be added for this figure}}
   \label{fig:synwkld-network-traffic}
\end{figure*}

\begin{figure*}[t!]
    \centering   
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{syn-wkld/gc-btime}
        \caption{Global Channel Busy Time}
        \label{fig:synwkld-global-channel-stime}
    \end{subfigure}%
     \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{syn-wkld/lc-btime}
        \caption{Local Channel Busy Time}
        \label{fig:synwkld-local-channel-stime}
    \end{subfigure}%
    \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.8 in]{syn-wkld/tl-btime}
        \caption{Terminal Link Busy Time}
        \label{fig:synwkld-terminal-link-stime}
    \end{subfigure}%
   \caption{Network Channel Busy Time. \textbf{More explanation to be added for this figure}}
   \label{fig:synwkld-network-stime}
\end{figure*}

\subsection{Individual Application Analysis}

The communication time of each application shown in Figure \ref{fig:syn-apps-commtime}. The ``bully" become the ``bullyee". The less communication-intensive applications in the workload this time are  MultiGrid and CrystalRouter.  When random placement coupled with (progressive) adaptive routing is used, MultiGrid and CrystalRouter suffer prolonged communication time, shown in Figure \ref{fig:syn-mg-commtime}, \ref{fig:syn-cr-commtime}. sAMG on the other hand benefit from random placement, shown in Figure \ref{fig:syn-samg-commtime}. 

Contiguous placement coupled with minimal routing prevent applications from sharing network resource, and confine application communication traffic to their allocated routers. This can guarantee the performance of less communication intensive applications like MultiGrid and CrystalRouter, and make the communication intensive application like sAMG severely deteriorate. 


\begin{figure*}[t!]
    \centering
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.5 in]{syn-wkld/amg10/commtime}
        \caption{sAMG Communication Time}
        \label{fig:syn-samg-commtime}
    \end{subfigure}%
    \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.5 in]{syn-wkld/mg/commtime}
        \caption{MG Communication Time}
        \label{fig:syn-mg-commtime}
    \end{subfigure}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.5 in]{syn-wkld/cr/commtime}
        \caption{CR Communication Time}
        \label{fig:syn-cr-commtime}
    \end{subfigure}%
   \caption{Application communication time. Three applications running concurrently on dragonfly network with different placement and routing configurations. Random placement and adaptive routing can improves AMG's communication time. MG and CR communication time are prolonged with random placement and adaptive routing.}
   \label{fig:syn-apps-commtime}
\end{figure*}

% explain the network status of sAMG, MG and CR
We look into the network level to scrutinize the traffic went through the routers belongs to each application. 
Figure \ref{fig:syn-samg-lc-traffic}, \ref{fig:syn-samg-gc-traffic} shows the traffic go through the local and global channels of the routers that belongs to sAMG when different placement and routing configuration is used. The traffic is skyrocketing in both local and global channels when contiguous placement coupled with minimal routing. The contiguous placement make all the MPI ranks of sAMG reside on a set of nodes in the groups that adjacent to each other and minimal routing confines the traffic in those groups, results in severe local congestion. When adaptive routing is used, the local congestion will be alleviated in both local and global channels, as some traffic will be redirected to other part of the network. Random placement scheme can further reduce the traffic burden on local and global channels by assigning each MPI rank of sAMG with randomly select nodes, thus uniformly distribute sAMG traffic over the network. 

MultiGrid become a victim of sAMG's bully when running under random placement. The traffic go through the local and global channels of the routers that belongs to MultiGrid are shown in Figure \ref{fig:syn-mg-lc-traffic}, \ref{fig:syn-mg-gc-traffic}. Although contiguous placement allocates all the MPI ranks in set of nodes in adjacent groups, causing possible local congestion, it will save MultiGrid's routers being shared by the traffic from its communication intensive peer, sAMG. As random placement is used, the traffic go through both local and global channels are greatly increased. 

CrystalRouter has more traffic than MultiGrid. The random placement won't redirect much traffic from other applications to the routers belongs to CrystalRouter, compared with contiguous placement, as shown in Figure \ref{fig:syn-cr-lc-traffic}, \ref{fig:syn-cr-gc-traffic}.


\begin{figure*}[t!]
    \centering
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.5 in]{syn-wkld/amg10/lc-traffic}
        \caption{sAMG Local Channel Traffic}
        \label{fig:syn-samg-lc-traffic}
    \end{subfigure}%
    \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.5 in]{syn-wkld/mg/lc-traffic}
        \caption{MG Local Channel Traffic}
        \label{fig:syn-mg-lc-traffic}
    \end{subfigure}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.5 in]{syn-wkld/cr/lc-traffic}
        \caption{CR Local Channel Traffic}
        \label{fig:syn-cr-lc-traffic}
    \end{subfigure}%
   \caption{Each Application Router Local Channel Traffic.  }
   \label{fig:syn-3app-lc-traffic}
\end{figure*}


\begin{figure*}[t!]
    \centering
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.5 in]{syn-wkld/amg10/gc-traffic}
        \caption{sAMG Global Channel Traffic}
        \label{fig:syn-samg-gc-traffic}
    \end{subfigure}%
    \hspace{1em}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.5 in]{syn-wkld/mg/gc-traffic}
        \caption{MG Global Channel Traffic}
        \label{fig:syn-mg-gc-traffic}
    \end{subfigure}%
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[height=1.5 in]{syn-wkld/cr/gc-traffic}
        \caption{CR Global Channel Traffic}
        \label{fig:syn-cr-gc-traffic}
    \end{subfigure}%
   \caption{Each Application Router Global Channel Traffic.}
   \label{fig:syn-3app-gc-traffic}
\end{figure*}




\section{Summary}

Based on the results we got from both real application traces and synthetic workload, we can make the following observations:

\begin{itemize}
    \item Random placement and adaptive routing can uniformly distribute workload traffic over the network, make the whole network load-balanced and hot-spot free. 
    \item Random placement and adaptive routing can not guarantee QoS for each application in the workload. In order to reach load-balanced and hot-spot free, the traffic from congested routers will be redirected to other less busy routers. This will indulge the ``bully" that communication-intensive applications impose to their less intensive peers. 
    \item Contiguous placement and minimal routing guarantee a consistent performance of each application. Although, contiguous placement and minimal routing usually results in local congestion and hot-spot, it can reduce the interference between concurrently running applications, thus prevent less communication-intensive application from being ``bully" by its intensive peers.
\end{itemize}


According to our findings, we believe choosing the ideal placement and routing strategies for workload running on dragonfly network should be based on application's communication intensity. The less intensive applications should avoid sharing network resource with other applications, reduce the possible interference. Contiguous placement and adaptive routing can guarantee the QoS for the less intensive applications, thus prevent the ``bully" from happening. 

The communication-intensive applications tend to cause local congestion. It is preferable to enable communication-intensive applications to have extra network resource by sharing with other applications.  Random placement and adaptive routing can alleviate the local congestion by redirecting traffic to other less busy routers in the network. 

So the ideal placement and routing strategies for workload running on dragonfly network should be like this. The communication-intensive applications should be randomly allocated over the system and adaptive routing should be used by these applications to alleviate the local congestion. On the other hand, less intensive application should get contiguous allocation, minimal routing should be used by these applications to avoid network sharing and reduce interference. 
 


\section{Related Work}
\label{sec:related work}

The impact of job placement to both system and application always catch researchers appetite \cite{dskinner} \cite{abhinav-sc13} \cite{jose-ipdps15}. Skinner et al.\cite{dskinner} identified that network congestion could cause significant performance variability. Bhatele et al. \cite{abhinav-sc13} studied the performance variability of a specific application, p3FD, running on different production system. They noticed that the application performance would keep consistent when it got compact allocation and exclusive network resource. Jokanovic et al.\cite{jose-ipdps15} study the impact of job placement to the workload and claimed that the key to reduce performance variability is to avoid network sharing. 

Recently, several researchers have investigated the job placement and routing schemes on dragonfly network. Bogdan et al \cite{hoefler-hpdc14} proposed novel solution for mapping tasks of application that conforms to Nearest Neighbor communication pattern on dragonfly network. Jain et al. \cite{jain-sc14} conducted a comprehensive analysis of various job placement and routing scheme with regard to network link throughput on dragonfly network. Their work is based on an analytical model and synthetic workload. Bhatele et al.\cite{bhatele-sc11} used simulation to study the performance of synthetic workload under the different task mapping and routing schemes on two-level direct networks.


Our work different from the previous works in the following ways. First, instead of using synthetic workload that generated based on predefined communication patterns, our simulation is driven real application traces collected from production system. Second, not only we care about the workload performance, but also we pay attention to each individual application in the workload. We found that although random placement and adaptive routing can improve the workload performance, some specific application in the workload may suffer performance degradation. Third, with the sophisticated simulation tool CODES, we can get not only applications communication information, but also we have the insight about the network status when application is running. The traffic and busy time of router's each link are valuable information for detailed analysis.

\section{Conclusion}
\label{sec:conclusion}

In this paper, we have conducted extensive study about application's behavior when it running on dragonfly network with different job placement and routing configurations. We resorted to CODES, a HPC network simulation tool with high fidelity, and used three parallel applications traces collected from production system to analysis the applications' behavior on network level. We found that when applications are running concurrently, although random placement can uniformly distribute the workload traffic over the network, alleviate local congestion, the performance of certain application would be impaired. We identify this phenomenon as ``bully" between concurrently running jobs, and the victim always being the less communication-intensive application. On the other hand, the contiguous placement tend to cause local congestion, however when coupled with adaptive routing, the configuration can guarantee the performance of ``bullee" application by limiting the network sharing between concurrently running application. 

Due the presence of this ``bully", we suggest that when the batch scheduler make job placement for workload on system with dragonfly network, random placement shouldn't be the rule of thumb. Instead, the placement should made with consideration of jobs communication intensity. The less intensive application should get contiguous allocation coupled with adaptive routing, the intensive ones should get random allocation coupled with minimal routing. 

We believe the findings presented in this paper can illuminate a path to more efficient workload manager for future systems with dragonfly network.



% conference papers do not normally have an appendix



% use section* for acknowledgment
\ifCLASSOPTIONcompsoc
  % The Computer Society usually uses the plural form
  \section*{Acknowledgments}
\else
  % regular IEEE prefers the singular form
%   \section*{Acknowledgment}
\fi


The work at Illinois Institute of Technology is supported in part by U.S. National Science Foundation grants CNS-1320125 and CCF-1422009. This work is also supported by the U.S. Department of Energy, Office of Science, Advanced Scientific Computing Research, under Contract DE-AC02-06CH11357.


% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{4}


\bibliographystyle{IEEEtran}
\bibliography{./reference}  


% \vspace{5\baselineskip}
% 
% \begin{framed}
% The submitted manuscript has been created by UChicago Argonne, LLC, Operator of Argonne National Laboratory ("Argonne").  Argonne, a U.S. Department of Energy Office of Science laboratory, is operated under Contract No. DE-AC02-06CH11357.  The U.S. Government retains for itself, and others acting on its behalf, a paid-up nonexclusive, irrevocable worldwide license in said article to reproduce, prepare derivative works, distribute copies to the public, and perform publicly and display publicly, by or on behalf of the Government.
% \end{framed}




% that's all folks
\end{document}


