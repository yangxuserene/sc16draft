\section{Introduction}
\label{sec:intro}

Low-latency and high-bandwidth interconnect networks play a critical role in ensuring HPC system performance. 
The high-radix, low-diameter dragonfly topology can lower the overall cost of the interconnect, improve network bandwidth and reduce packet latency \cite{dally-dragonfly}, 
making it a very promising choice for building supercomputers with millions of cores.
Even with such powerful networks, 
intelligent job placement is of paramount importance to the efficient use of dragonfly connected systems~\cite{bhatele2015, jain-sc14}. 
%An ideal job placement policy should not only load balance the network 
%but also guarantee the performance of every single application by minimizing the inevitable interference on the dragonfly network.  

Recent studies suggest that random node allocation for parallel jobs, coupled
with adaptive routing, can alleviate local congestion, eliminate hot-spots and achieve load-balancing for dragonfly networks~\cite{jain-sc14, bhatele-sc11, brandt2014}. 
These works explore the possible job placement and routing configurations that could optimize the overall network performance without examining how different configurations impact the progress of individual applications.
In this paper, we study the implications of contention for shared network links in the context of multiple HPC applications running on dragonfly systems when different job placement and routing configurations are in use.
Our analyses focus on the overall network performance as well as the performance of concurrently executing applications in the presence of network contention.

%We have observed that when running concurrently on the dragonfly network, applications interfere with each other and the less communication-intensive applications are ``bullied" by the communication-intensive ones. The ``bully" applications get great performance improvement at the cost of performance degradation to the ``bullied" applications. We choose three representative applications from the DOE Design Forward Project~\cite{designforwardwebpage} to study the root cause of the ``bullying" with simulation on CODES, an high-fidelity, packet-level HPC network simulation toolkit~\cite{codes}. 


We choose three representative HPC applications from the DOE Design Forward Project~\cite{designforward-webpage} and analyze the interference among them. Our study is based on simulation with CODES, a high-fidelity, flit-level HPC network simulation toolkit~\cite{misbah-tpds}. 
For each application, we examine its performance with two job placement policies and three routing policies.
We make the following observations through extensive simulations.


%In this work, we study the interference between concurrently running jobs on dragonfly networks with different job placement and routing policies. We use CODES, an HPC network simulation toolkit with high fidelity and excellent scalability for packet level simulation \cite{codes}. Unlike much existing work that rely on synthetic workloads, we use traces of three representative applications from the DOE Design Forward Project \cite{designforwardwebpage}. The advantage of using real application traces is straight forward: these traces can capture detailed application communication behaviors that are omitted in synthetic workload for simplification. Applications are usually distinctive from each other in data transfer amount, communication pattern, operation dependency etc., which can be impractical to reproduce in a synthetic workload.

%We conduct extensive experiments with three applications running on dragonfly network with two job placement policies and three routing policies. We analyze the performance of network as well as individual application when running with different placement and routing configurations. Our evaluation is based on more than 1000 runs of simulation. We make the following interesting observations through extensive simulation.


\begin{itemize}
   
    \item Concurrently running applications on a dragonfly network interfere with each other when they share network resources. Communication-intensive applications ``bully" their less intensive peers and obtain performance improvement at the expense of less intensive ones. 
    
    \item Random placement of application processes in the dragonfly can improve the performance of communication-intensive applications by enabling network resource sharing, though it introduces interference causing performance degradation to the less intensive applications.
    
   \item Contiguous placement can be beneficial to the consistent performance of less communication-intensive applications by minimizing network resource sharing, because it reduces the opportunities for traffic from other applications to be loaded on links that serve as minimal routes for the less intensive application. However, this comes with the downside of at times greatly reduced system performance via load imbalance.
    
    
\end{itemize}

Based on the aforementioned key observations, one would expect that an ideal job placement policy on dragonfly systems would take relative communication intensity into account, and mix contiguous and non-contiguous placement based on application needs. To explore this expectation, we investigate a hybrid job placement policy, which assigns random allocations to communication-intensive applications and contiguous allocations to less intensive ones. Initial experimentation shows that hybrid job placement aids in reducing the worst-case performance degradation for less communication-intensive applications while retaining the performance of communication-intensive applications, though without eliminating the problem entirely.
%\emph{The random placement and adaptive routing are preferable to communication-intensive jobs, whereas contiguous placement and minimal routing are in favor of less intensive jobs.} 
To the best of our knowledge, using real application traces from production systems for the study of job interference on dragonfly networks has not been reported in the literature so far. We believe the observations and new placement policy presented in this paper are valuable to the HPC community.
%We believe the observations and new placement policy presented in this paper are valuable to a number of communities including HPC computing centers, system software developers, and system administrators. 
%For example, the computing centers should take resource sharing into consideration when choosing proper configurations for building their dragonfly networks. System software developers could design better scheduling algorithms for jobs with distinct communication behavior. System administrators could make more accurate predication about system availability based on job running status under different placement and routing configurations.


The rest of this paper is organized as follows. Section~\ref{sec:background} describes an implementation of the dragonfly network, introduces the placement policies and routing policies. Section~\ref{sec: methodology} talks about the use of CODES as a research vehicle and three representative applications from the DOE Design Forward Project. Section~\ref{sec:workload-1} presents the observations and analysis of three applications running on a dragonfly network with different placement and routing configurations. Section~\ref{sec:workload-2} validates the observations we obtain from previous section. Section~\ref{sec: hybrid placement} presents a alternative placement policy for the dragonfly network. Section~\ref{sec:related work} discusses the related work. Finally, the conclusion is presented in Section~\ref{sec:conclusion}.


