

\section{Methodology}
\label{sec: methodology}

Configurable dragonfly networks that allow us to perform the exploration presented in this paper are hard to come by for the time being. Even with access to systems with such networks, job placement and routing policies are part of system configuration, which is impossible for user to make changes at will~\cite{jain-sc14, bhatele-sc11, zhou-ipdps-2015, jokanovic-ipdps-2015}. Therefore, we resort to simulation in our work.


%It is difficult to experiment with concurrently running jobs on HPC systems~\cite{zhou-ipdps-2015}\cite{jain-sc14}\cite{bhatele-sc11}\cite{jokanovic-ipdps-2015}. One reason is that job placement and routing policies are part of system configuration, which is impossible for user to make changes at will. Another reason is that it is unrealistic to reserve the system exclusively to run the same batch of jobs with desired placement and routing configurations and compare the results. The third reason is that configurable dragonfly networks that allow us to perform the exploration presented in this paper are hard to come by for the time being. Therefore, we resort to simulation in our work.

\subsection{Simulation Tool}
\label{sec:simulation-tool}

We utilize the CODES simulation toolkit (Co-Design of Multilayer Exascale Storage Architectures)~\cite{codes}, which builds upon the ROSS parallel discrete event simulator~\cite{carothers_ross:_2002,barnes_warp_2013} to enable exploratory study of large scale systems of interest to the HPC community. CODES supports dragonfly~\cite{codes-dragonfly, misbah-tpds}, torus~\cite{misbah-pads-2014, ning-pads-2011}, and fat-tree~\cite{ning-pads-2015} networks with flit-level high-fidelity simulation. It can drive these models through an MPI simulation layer utilizing traces generated by the DUMPI MPI tracer~\cite{sst}.

\subsection{Parallel Applications}
\label{sec: application traces}

We use a trace-driven approach to workload generation, choosing in particular three parallel application traces gathered to represent exascale workload behavior as part of the DOE Design Forward Project~\cite{designforwardwebpage} \TODO{can we get a better cite?}. Specifically, we study communication traces representing the \emph{Algebraic MultiGrid Solver} (AMG), \emph{Geometric Multigrid V-Cycle from Production Elliptic Solver} (MultiGrid) and \emph{Crystal Router MiniApp} (CrystalRouter).

\textbf{AMG:} The Algebraic MultiGrid Solver is a parallel algebraic multi-grid solver for linear systems arising from problems on unstructured mesh physics packages. It has been derived directly from the BoomerAMG solver developed in the Center for Applied Scientific Computing (CASC) at LLNL~\cite{amg}. 


\textbf{MultiGrid:} The geometric multi-grid v-cycle from the production elliptic solver BoxLib is a software framework for massively parallel block-structured adaptive mesh refinement (AMR) codes~\cite{boxlib}, which are used in structured grid physics packages. 

\textbf{CrystalRouter:} The Crystal Router MiniApp is a communication kernel of Nek5000~\cite{nek5000}, a spectral element CFD application developed at Argonne National Laboratory. It features spectral element multi-grid solvers coupled with a highly scalable, parallel coarse-grid solver that is widely used for projects including ocean current modeling, thermal hydraulics of reactor cores, and spatiotemporal chaos. 




\subsection{System Configuration}
\label{sec: simulation configuration}

The parameters for building the dragonfly network studied in our work are informed by the model proposed by Kim et al.~\cite{kim-micro}. Our dragonfly network consists of 33 groups, each containing eight routers. Each router has four compute nodes attached to it. Overall, there are 264 routers and 1056 compute nodes in the network. \TODO{What's the resulting router radix?} The aggregate bandwidth of the terminal links, as well as the local and global channels, are proportional to those of the Cray Cascade system~\cite{faanes} \TODO{What are these bandwidths?}. In this work, we simulate the network performance and job interference across six different job placement and routing policy combinations, which are summarized in Table~\ref{tab: placement routing configs}.

%\footnote{With respect to random placement, we experiment with 50 sets of distinctive allocation generated by random placement. The corresponding experimental results are median chosen, which intended to eliminate the possibility of variation.}

\begin{table}[ht]
\begin{center}
\caption{The notation for different placement and routing configurations} 
\label{tab: placement routing configs}
\begin{tabular}{l c c c }
\toprule % Top horizontal line
\toprule
&\multicolumn{3}{c}{Routing Policies} \\ 
\cmidrule(l){2-4}
Placement Policies & Minimal & Adaptive & Progressive Adaptive\\ % Column names row
\midrule % In-table horizontal line
Contiguous  &  CM   &   CA   &  CPA   \\ % Content row 1
\midrule
Random  &   RM  &   RA   &  RPA   \\ 
\midrule % In-table horizontal line
\bottomrule % Bottom horizontal line
\end{tabular}
\end{center}
\end{table}


We analyze both the overall network performance and the performance of every single application.
Our analysis focuses on the following metrics:
\begin{itemize}

    \item \textbf{Network Traffic:} The traffic refers to the amount of data going through each router. We analyze the traffic on the terminal link, local and global channel of each router. The network reaches optimal performance when the traffic is uniformly distributed and no particular router is over-loaded. 
            
    \item \textbf{Network Saturation Time:} The saturation time refers to the time period when the buffer of a certain port in the router is full. We analyze the saturation time of ports corresponding to terminal links, local and global channels. The saturated time indicates the congestion level of routers. 
    
    \item \textbf{Communication Time:} The communication time of each MPI rank refers to the time it spends in completing all its message exchanges with other ranks. Due to our use of simulation, we are able to measure the absolute (simulated) time a message takes to reach its destination. \TODO{Verify this. Or is comm time the time that the terminal link is busy?} The performance of each application is measured by the \TODO{max? avg across ranks? distribution?} communication time.
\end{itemize}

Note that we do not model computation for each MPI rank due to both the complexities inherent in performance prediction on separate parallel architectures as well as the emphasis on the side of the Design Forward traces on communication behavior rather than compute representation; users are instructed to treat the traces as if they came from one MPI rank-per-node configuration, despite being gathered using a rank-per-core approach. We instead allow MPI communications to proceed as quickly as they are able. \TODO{is this a good enough explanation? Anything else we should add?}

\subsection{Workload Summary}
\label{sec:workload summary}

Two sets of parallel workloads are used in this study. Workload~\Rmnum{1} consists of AMG, MultiGrid and CrystalRouter. As shown in Table~\ref{tab:apps-detail}, AMG has the least amount of data transfer, making it the least communication-intensive job in the workload. Workload~\Rmnum{2} consists of sAMG, MultiGrid and CrystalRouter. sAMG, a synthetic version of AMG, is generated by increasing the data transferred in AMG's MPI calls by a factor of 100, making it the most communication-intensive job in the workload. We do this for reasons that will become clear in the following sections.

Each rank of each application is run on a dedicated node, following the recommended interpretation of the traces by the Design Forward team.

%Table \ref{tab:apps-detail} summarizes the details of each application. It shows the number of MPI ranks, the average data transfer amount of each rank and the total data transfer amount for each application.

\begin{table}[ht]
\begin{center}
\caption{Application Summaries}
\label{tab:apps-detail}
\begin{tabular}{l c c c }
\toprule % Top horizontal line
\toprule
App Name & Num. Rank & Avg. Data/Rank & Total Data\\ % Column names row
\midrule % In-table horizontal line
AMG  &    216 &   0.6MB   &     130MB\\ % Content row 1
\midrule
MultiGrid  &    125 &   5MB   &     625MB\\ 
\midrule
CrystalRouter  &   100  &  35MB    &     3500MB\\ 
\midrule
sAMG  &    216 &   60MB   &     13000MB\\ % Content row 1
\midrule % In-table horizontal line
\bottomrule % Bottom horizontal line
\end{tabular}
\end{center}
\end{table}

